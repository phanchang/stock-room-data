import sys
import os
from pathlib import Path
from dotenv import load_dotenv

# è¼‰å…¥ .env ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šå°ˆæ¡ˆè·¯å¾‘ - å¾ç•¶å‰æª”æ¡ˆå¾€ä¸Šæ‰¾åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent

sys.path.insert(0, str(project_root))

from utils.etf.scheduler import ETFScheduler
from modules.scrapers.ezmoney import EZMoneyScraper
from modules.scrapers.fhtrust import FHTrustScraper

# å‹•æ…‹è¨­å®šåŸºç¤ç›®éŒ„
# main.py ä½ç½®: æˆ°æƒ…å®¤/modules/scrapers/main.py
# ç›®æ¨™è·¯å¾‘: æˆ°æƒ…å®¤/data/raw
# è·¯å¾‘æ¨ç®—: main.py -> scrapers -> modules -> æˆ°æƒ…å®¤ -> /data/raw
BASE_DIR = current_file.parent.parent.parent / 'data' / 'raw'

# Proxy è¨­å®š - å¾ .env è®€å–ï¼Œå®¶è£¡ä¸ç”¨è¨­å®š
PROXY_HOST = os.getenv('PROXY_HOST')
PROXY_PORT = os.getenv('PROXY_PORT')
PROXY = f"{PROXY_HOST}:{PROXY_PORT}" if PROXY_HOST and PROXY_PORT else None

SCRAPERS = {
    'ezmoney': {
        'class': EZMoneyScraper,
        'funds': [
            {'code': '49YTW', 'name': '00981A', 'dir': 'ezmoney/00981A'}
        ],
        'schedule_time': '15:30'
    },
    'fhtrust': {
        'class': FHTrustScraper,
        'funds': [
            {'code': 'ETF23', 'name': '00991A', 'dir': 'fhtrust/00991A'}
        ],
        'schedule_time': '15:30'
    }
}

def manual_fetch_all():
    """æ‰‹å‹•æŠ“å–æ‰€æœ‰æŠ•ä¿¡"""
    print("=" * 60)
    print("æ‰‹å‹•æŠ“å–æ¨¡å¼ - æŠ“å–æ‰€æœ‰æŠ•ä¿¡")
    print("=" * 60)

    for company, config in SCRAPERS.items():
        print(f"\n### {company.upper()} ###")
        scraper_class = config['class']

        for fund in config['funds']:
            print(f"\nè™•ç† {fund['name']} ({fund['code']})...")
            save_dir = BASE_DIR / fund['dir']
            save_dir.mkdir(parents=True, exist_ok=True)

            scraper = scraper_class(
                fund_code=fund['code'],
                save_dir=str(save_dir),
                proxy=PROXY
            )

            scraper.fetch_and_save()


def manual_fetch_specific(company, fund_name=None):
    """æ‰‹å‹•æŠ“å–ç‰¹å®šæŠ•ä¿¡æˆ–åŸºé‡‘"""
    print("=" * 60)
    print(f"æ‰‹å‹•æŠ“å–æ¨¡å¼ - {company.upper()}")
    print("=" * 60)

    if company not in SCRAPERS:
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŠ•ä¿¡ '{company}'")
        print(f"å¯ç”¨çš„æŠ•ä¿¡: {', '.join(SCRAPERS.keys())}")
        return

    config = SCRAPERS[company]
    scraper_class = config['class']

    funds_to_process = config['funds']
    if fund_name:
        funds_to_process = [f for f in config['funds'] if f['name'] == fund_name]
        if not funds_to_process:
            print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åŸºé‡‘ '{fund_name}'")
            return

    for fund in funds_to_process:
        print(f"\nè™•ç† {fund['name']} ({fund['code']})...")
        save_dir = BASE_DIR / fund['dir']
        save_dir.mkdir(parents=True, exist_ok=True)

        scraper = scraper_class(
            fund_code=fund['code'],
            save_dir=str(save_dir),
            proxy=PROXY
        )

        scraper.fetch_and_save()


def run_scheduler():
    """å•Ÿå‹•æ’ç¨‹å™¨"""
    # ç¢ºä¿è³‡æ–™ç›®éŒ„å­˜åœ¨
    BASE_DIR.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸ“ è³‡æ–™å„²å­˜è·¯å¾‘: {BASE_DIR}")
    print(f"ğŸŒ Proxy è¨­å®š: {PROXY if PROXY else 'æœªè¨­å®š (ç›´é€£)'}\n")

    # åˆå§‹åŒ–æ’ç¨‹å™¨
    scheduler = ETFScheduler(
        scrapers_config=SCRAPERS,
        base_dir=str(BASE_DIR),
        proxy=PROXY,
        retry_interval=30,
        max_retry_until="23:59",
        startup_check_days=7  # æª¢æŸ¥ç¯„åœï¼šéå»7å¤©ï¼Œä½†åªä¸‹è¼‰ç¼ºå¤±çš„æ—¥æœŸ
    )
    scheduler.run()


def print_help():
    """é¡¯ç¤ºä½¿ç”¨èªªæ˜"""
    print("çµ±ä¸€ ETF çˆ¬èŸ²ç³»çµ± - ä½¿ç”¨èªªæ˜")
    print("=" * 60)
    print("åŸºæœ¬ç”¨æ³•:")
    print("  python main.py                    # å•Ÿå‹•æ’ç¨‹å™¨")
    print("  python main.py --now              # ç«‹å³æŠ“å–æ‰€æœ‰æŠ•ä¿¡")
    print("  python main.py --now ezmoney      # ç«‹å³æŠ“å– EZMoney")
    print("  python main.py --now fhtrust      # ç«‹å³æŠ“å–å¾©è¯æŠ•ä¿¡")
    print("  python main.py --help             # é¡¯ç¤ºæ­¤èªªæ˜")
    print(f"\nğŸ“ è³‡æ–™å„²å­˜ä½ç½®: {BASE_DIR}")
    print("\nå¯ç”¨çš„æŠ•ä¿¡:")
    for company, config in SCRAPERS.items():
        print(f"  - {company}")
        for fund in config['funds']:
            print(f"    * {fund['name']} ({fund['code']})")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        cmd = sys.argv[1]

        if cmd in ['--now', '-n']:
            if len(sys.argv) > 2:
                company = sys.argv[2]
                fund_name = sys.argv[3] if len(sys.argv) > 3 else None
                manual_fetch_specific(company, fund_name)
            else:
                manual_fetch_all()

        elif cmd in ['--help', '-h']:
            print_help()

        else:
            print(f"æœªçŸ¥åƒæ•¸: {cmd}")
            print_help()
    else:
        run_scheduler()