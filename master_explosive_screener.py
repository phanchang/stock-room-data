import pandas as pd
import numpy as np
from pathlib import Path
import sys

# ç¢ºä¿è¼‰å…¥ utils
project_root = Path(__file__).resolve().parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from utils.strategies.technical import TechnicalStrategies


def generate_explosive_master_table():
    print("ğŸš€ å•Ÿå‹•ã€ç§‘æŠ€è‚¡åŠ æ¬Šå‡ç´šç‰ˆã€‘ä¸‰ç¶­åº¦é‡åŒ–é¸è‚¡æ¨¡å‹...")

    chips_path = project_root / "data" / "temp" / "chips_revenue_raw.csv"
    if not chips_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°ç±Œç¢¼æª”æ¡ˆ: {chips_path}")
        return

    df_chips = pd.read_csv(chips_path, dtype={'sid': str})

    numeric_cols = ['rev_yoy', 'rev_cum_yoy', 'pe', 'yield', 'f_sum_5d', 't_sum_5d',
                    'm_sum_5d', 's_sum_5d', 'f_streak', 't_streak', 'is_tu_yang']
    for col in numeric_cols:
        if col in df_chips.columns:
            df_chips[col] = pd.to_numeric(df_chips[col], errors='coerce').fillna(0)

    # æ¨™è¨˜æ˜¯å¦ç‚ºç§‘æŠ€/é›»å­è‚¡ (ç”¢æ¥­ç´…åˆ©)
    tech_keywords = ['åŠå°é«”', 'é›»å­', 'é›»è…¦', 'å…‰é›»', 'é€šä¿¡', 'ç¶²é€š', 'é›¶çµ„ä»¶', 'è³‡è¨Š']
    df_chips['is_tech'] = df_chips['industry'].astype(str).apply(lambda x: any(k in x for k in tech_keywords)).astype(
        int)

    master_records = []
    base_cache_path = project_root / "data" / "cache" / "tw"

    print("ğŸ”„ æ­£åœ¨è®€å– K ç·šï¼ŒåŸ·è¡Œç¨ç«‹è£ç”²ç‰¹å¾µé‹ç®—...")
    for idx, row in df_chips.iterrows():
        sid = row['sid']
        path_tw = base_cache_path / f"{sid}_TW.parquet"
        path_two = base_cache_path / f"{sid}_TWO.parquet"
        file_path = path_two if path_two.exists() else path_tw

        tech = {
            'above_150ma': 0, 'is_consolidation': 0, 'comp_days_60': 0,
            'has_30w_sig_15d': 0, 'has_vol_spike_15d': 0, 'has_shk_15d': 0,
            'strong_uptrend': 0, 'supertrend_dir': 0, 'breakout_high': 0
        }

        if file_path.exists():
            try:
                df_kline = pd.read_parquet(file_path)
                if len(df_kline) >= 160:
                    df_kline.rename(columns=lambda x: x.capitalize() if x.lower() in ['open', 'high', 'low', 'close',
                                                                                      'volume'] else x, inplace=True)
                    ma150 = df_kline['Close'].rolling(150).mean()

                    try:
                        tech['above_150ma'] = int(df_kline['Close'].iloc[-1] > ma150.iloc[-1])
                    except:
                        pass

                    try:
                        ma20 = df_kline['Close'].rolling(20).mean()
                        std20 = df_kline['Close'].rolling(20).std()
                        bb_width = (4 * std20) / ma20 * 100
                        # ç¨å¾®æ”¾å¯¬ç§‘æŠ€è‚¡çš„å£“ç¸®å®šç¾©è‡³ 18ï¼Œé¿å…éŒ¯æ®º
                        tech['is_consolidation'] = int(bb_width.iloc[-1] < 25)
                        tech['comp_days_60'] = int((bb_width.tail(60) < 25).sum())
                    except:
                        pass

                    try:
                        vol_20ma = df_kline['Volume'].rolling(20).mean()
                        is_vol_spike = df_kline['Volume'] > (1.5 * vol_20ma.shift(1))
                        tech['has_vol_spike_15d'] = int(is_vol_spike.tail(15).any())
                    except:
                        pass

                    try:
                        adh_series = (abs(df_kline['Close'] - ma150) / ma150) < 0.04
                        shk_series = (df_kline['Close'] > ma150) & (df_kline['Close'].shift(1) < ma150.shift(1))
                        has_adh = adh_series.tail(15).any()
                        has_shk = shk_series.tail(15).any()

                        if hasattr(TechnicalStrategies, 'strategy_30w_adherence'):
                            res = TechnicalStrategies.strategy_30w_adherence(df_kline)
                            has_adh = res.tail(15).any() if isinstance(res, pd.Series) else bool(res)

                        if hasattr(TechnicalStrategies, 'strategy_30w_shakeout'):
                            res = TechnicalStrategies.strategy_30w_shakeout(df_kline)
                            has_shk = res.tail(15).any() if isinstance(res, pd.Series) else bool(res)

                        tech['has_30w_sig_15d'] = int(has_adh or has_shk)
                        tech['has_shk_15d'] = int(has_shk)
                    except:
                        pass

                    try:
                        st_df = TechnicalStrategies.calculate_supertrend(df_kline)
                        tech['supertrend_dir'] = int(st_df['Direction'].iloc[-1]) if not st_df.empty else 0
                        tech['strong_uptrend'] = int(TechnicalStrategies.strong_uptrend(df_kline).iloc[-1])
                        tech['breakout_high'] = int(
                            TechnicalStrategies.breakout_n_days_high(df_kline, window=20).iloc[-1])
                    except:
                        pass

            except Exception as e:
                pass

        merged_row = {**row.to_dict(), **tech}
        master_records.append(merged_row)

    df_master = pd.DataFrame(master_records).fillna(0)

    print("âš¡ æ­£åœ¨åŸ·è¡Œéšæ¢¯å¼è¨ˆåˆ†èˆ‡ã€ç§‘æŠ€è‚¡ç”¢æ¥­åŠ æ¬Šã€‘...")

    # ã€ä¿®æ­£ EPS ç‚º 0 çš„å•é¡Œã€‘ç”¨ PE > 0 ä¸” PE < 40 æ›¿ä»£æœ‰è³ºéŒ¢çš„è­‰æ˜
    is_profitable = ((df_master['pe'] > 0) & (df_master['pe'] < 40)).astype(int)

    # ==========================================
    # ğŸ›¡ï¸ éƒ¨éšŠä¸€ï¼šé»ƒé‡‘æ½›ä¼ (æ»¿åˆ† 12åˆ†ï¼Œå«ç§‘æŠ€åŠ æ¬Š)
    # ==========================================
    score_t1_base = is_profitable * 2 + (df_master['rev_yoy'] > 5).astype(int) + \
                    (df_master['rev_yoy'] > 15).astype(int) + (df_master['rev_yoy'] > 30).astype(int)
    score_t1_chips = ((df_master['f_sum_5d'] + df_master['t_sum_5d']) > 0).astype(int) * 2 + \
                     ((df_master['f_streak'] >= 3) | (df_master['t_streak'] >= 3)).astype(int) * 2
    score_t1_retail = (df_master['m_sum_5d'] < 0).astype(int)

    # ç§‘æŠ€è‚¡åŠ æ¬Š (+2åˆ†)
    score_t1_tech_bonus = df_master['is_tech'] * 1

    df_master['T1_Score'] = score_t1_base + score_t1_chips + score_t1_retail + score_t1_tech_bonus
    df_master['T1_Valid'] = ((df_master['above_150ma'] == 1) & (df_master['is_consolidation'] == 1)).astype(int)

    # ==========================================
    # âš”ï¸ éƒ¨éšŠäºŒï¼šçªç ´äº¤æ˜“ (æ»¿åˆ† 12åˆ†ï¼Œå«ç§‘æŠ€åŠ æ¬Š)
    # ==========================================
    score_t2_comp = (df_master['comp_days_60'] > 10).astype(int) + (df_master['comp_days_60'] > 20).astype(int) + \
                    (df_master['comp_days_60'] > 30).astype(int) + (df_master['comp_days_60'] > 40).astype(int)
    score_t2_tech = (df_master['has_shk_15d'] == 1).astype(int) * 2
    score_t2_base = is_profitable * 2 + (df_master['rev_yoy'] > 0).astype(int) * 2
    score_t2_tech_bonus = df_master['is_tech'] * 2

    df_master['T2_Score'] = score_t2_comp + score_t2_tech + score_t2_base + score_t2_tech_bonus
    df_master['T2_Valid'] = ((df_master['above_150ma'] == 1) &
                             (df_master['has_30w_sig_15d'] == 1) &
                             (df_master['has_vol_spike_15d'] == 1)).astype(int)

    # ==========================================
    # ğŸš€ éƒ¨éšŠä¸‰ï¼šå¼·å‹¢è¿½åƒ¹ (æ»¿åˆ† 12åˆ†ï¼Œå«ç§‘æŠ€åŠ æ¬Š)
    # ==========================================
    score_t3_rev = (df_master['rev_yoy'] > 20).astype(int) * 4
    score_t3_short = (df_master['s_sum_5d'] > 0).astype(int) * 3
    score_t3_break = (df_master['breakout_high'] == 1).astype(int) * 3
    score_t3_tech_bonus = df_master['is_tech'] * 2

    df_master['T3_Score'] = score_t3_rev + score_t3_short + score_t3_break + score_t3_tech_bonus
    df_master['T3_Valid'] = ((df_master['strong_uptrend'] == 1) &
                             (df_master['supertrend_dir'] == 1) &
                             ((df_master['f_streak'] >= 3) | (df_master['t_streak'] >= 3))).astype(int)

    # ==========================================
    # ç¯©é¸èˆ‡ç”¢å‡ºå ±è¡¨
    # ==========================================
    valid_df = df_master[(df_master['pe'] < 100) | (df_master['pe'] == 0)]

    t1_top10 = valid_df[valid_df['T1_Valid'] == 1].sort_values(by=['T1_Score', 'rev_yoy'],
                                                               ascending=[False, False]).head(10)
    t2_top10 = valid_df[valid_df['T2_Valid'] == 1].sort_values(by=['T2_Score', 'comp_days_60'],
                                                               ascending=[False, False]).head(10)
    t3_top10 = valid_df[valid_df['T3_Valid'] == 1].sort_values(by=['T3_Score', 'rev_yoy'],
                                                               ascending=[False, False]).head(10)

    output_path = project_root / "data" / "temp" / "master_explosive_table.csv"
    df_master.to_csv(output_path, index=False, encoding='utf-8-sig')

    print("\nğŸ›¡ï¸ ã€æˆ°ç•¥ä¸€ï¼šé»ƒé‡‘ç§‘æŠ€æ½›ä¼ Top 10ã€‘ (ä¸æ¥åˆ€ã€ç›¤æ•´ä¸­ã€æœ¬ç›Šæ¯”ä¿è­·ã€æ³•äººå·è²·):")
    if not t1_top10.empty:
        t1_disp = t1_top10[['sid', 'name', 'industry', 'T1_Score', 'rev_yoy', 'pe', 'comp_days_60']]
        t1_disp.columns = ['ä»£è™Ÿ', 'åç¨±', 'ç”¢æ¥­', 'åˆ†æ•¸(æ»¿12)', 'ç‡Ÿæ”¶å¹´å¢%', 'PE', 'è¿‘60æ—¥å£“ç¸®å¤©æ•¸']
        print(t1_disp.to_string(index=False))
    else:
        print("  ç„¡ç¬¦åˆæ¨™çš„")

    print("\nâš”ï¸ ã€æˆ°ç•¥äºŒï¼šçªç ´äº¤æ˜“ Top 10ã€‘ (è¿‘15æ—¥å¸¶é‡èˆ‡30Wè¨Šè™Ÿã€å£“ç¸®è¶Šä¹…è¶Šé«˜åˆ†):")
    if not t2_top10.empty:
        t2_disp = t2_top10[['sid', 'name', 'industry', 'T2_Score', 'comp_days_60', 'has_shk_15d', 'pe']]
        t2_disp.columns = ['ä»£è™Ÿ', 'åç¨±', 'ç”¢æ¥­', 'åˆ†æ•¸(æ»¿12)', 'å£“ç¸®å¤©æ•¸', 'æœ‰ç„¡ç”©è½', 'PE']
        print(t2_disp.to_string(index=False))
    else:
        print("  ç„¡ç¬¦åˆæ¨™çš„")

    print("\nğŸš€ ã€æˆ°ç•¥ä¸‰ï¼šå¼·å‹¢è¿½åƒ¹ Top 10ã€‘ (çµ•å°å¤šé ­ã€æ³•äººç‹‚è²·ã€è»‹ç©ºèˆ‡æ¥­ç¸¾å‰µé«˜):")
    if not t3_top10.empty:
        t3_disp = t3_top10[['sid', 'name', 'industry', 'T3_Score', 'rev_yoy', 'f_streak', 't_streak']]
        t3_disp.columns = ['ä»£è™Ÿ', 'åç¨±', 'ç”¢æ¥­', 'åˆ†æ•¸(æ»¿12)', 'ç‡Ÿæ”¶å¹´å¢%', 'å¤–è³‡é€£è²·', 'æŠ•ä¿¡é€£è²·']
        print(t3_disp.to_string(index=False))
    else:
        print("  ç„¡ç¬¦åˆæ¨™çš„")

    # ==========================================
    # ç²¾æº–åŒ– AI Deep Research Prompt (åªæŒ‘æœ€å€¼å¾—é©—è­‰çš„)
    # ==========================================
    def get_prompt_targets(df):
        if df.empty: return "ç„¡"
        # å„ªå…ˆæŒ‘é¸ç§‘æŠ€è‚¡ï¼Œå†ä¾åˆ†æ•¸æ’åºï¼Œæœ€å¤šæŒ‘ 2 æª”
        tech_targets = df[df['is_tech'] == 1].head(2)
        if tech_targets.empty: tech_targets = df.head(1)
        return "ã€".join([f"{row['name']}({row['sid']})" for _, row in tech_targets.iterrows()])

    t1_targets = get_prompt_targets(t1_top10)
    t2_targets = get_prompt_targets(t2_top10)
    t3_targets = get_prompt_targets(t3_top10)

    prompt_content = f"""ä½ ç¾åœ¨æ˜¯ä¸€ä½æŒç®¡ç™¾å„„è³‡é‡‘çš„è¯çˆ¾è¡—é«˜ç››(Proprietary Trading)é¦–å¸­é‡åŒ–ç¶“ç†äººã€‚
æˆ‘å‰›é€éä¸€å¥—åš´æ ¼çš„ã€ä¸‰ç¶­åº¦æˆ°ç•¥é¸è‚¡æ¨¡å‹ã€‘(éæ¿¾äº†æ¥åˆ€é¢¨éšªï¼ŒåŠ å…¥äº†åŠå°é«”/é›»å­ç”¢æ¥­æ¬Šé‡ã€ä»¥åŠPEæœ¬ç›Šæ¯”ä¿è­·)ï¼Œç¯©é¸å‡ºäº†ä»¥ä¸‹åå–®ï¼š

ã€ğŸ›¡ï¸ é»ƒé‡‘æ½›ä¼éƒ¨éšŠ Top 10ã€‘ï¼š
{t1_top10[['sid', 'name', 'industry', 'T1_Score', 'rev_yoy', 'pe']].to_string(index=False) if not t1_top10.empty else "ç„¡"}

ã€âš”ï¸ çªç ´äº¤æ˜“éƒ¨éšŠ Top 10ã€‘ï¼š
{t2_top10[['sid', 'name', 'industry', 'T2_Score', 'comp_days_60']].to_string(index=False) if not t2_top10.empty else "ç„¡"}

ã€ğŸš€ å¼·å‹¢è¿½åƒ¹éƒ¨éšŠ Top 10ã€‘ï¼š
{t3_top10[['sid', 'name', 'industry', 'T3_Score', 'rev_yoy']].to_string(index=False) if not t3_top10.empty else "ç„¡"}

è«‹é‡å°é€™ä¸‰å€‹éƒ¨éšŠä¸­ï¼Œç³»çµ±ç‰¹æŒ‘å‡ºå¿…é ˆã€ŒDouble Confirmã€çš„æ ¸å¿ƒç§‘æŠ€æ¨™çš„ï¼š
- æ½›ä¼é©—è­‰ï¼šã€{t1_targets}ã€‘
- çªç ´é©—è­‰ï¼šã€{t2_targets}ã€‘
- è¿½åƒ¹é©—è­‰ï¼šã€{t3_targets}ã€‘

é€²è¡Œã€Œæ·±åº¦ç›¡è·èª¿æŸ¥ (Deep Research)ã€ã€‚(â—å‹™å¿…ä½¿ç”¨ Google Search æŸ¥è­‰æœ€æ–°æ³•èªªæœƒèˆ‡æ–°èï¼Œä¸å¹»æƒ³æ•¸æ“š)

è«‹æä¾›ã€å·®ç•°åŒ–äº¤æ˜“åŠ‡æœ¬èˆ‡åˆ©å¤šæŸ¥è­‰ã€‘ï¼š
1. æ½›ä¼éƒ¨éšŠï¼šæŒ–æ˜å…¶ç‡Ÿæ”¶åŸºæœ¬é¢è½‰æ©Ÿ(æ˜¯å¦æ¥åˆ°å¤§å» è¨‚å–®?)ï¼Œä¸¦è©•ä¼°ç›®å‰çš„ PE æ˜¯å¦ç¢ºå¯¦ä½ä¼°ï¼Ÿçµ¦å‡ºå·¦å´è²·é»å€é–“ã€‚
2. çªç ´éƒ¨éšŠï¼šæŸ¥è­‰è¿‘æœŸçš„çˆ†é‡åˆ©å¤šæ˜¯ä»€éº¼ï¼Ÿåš´æ ¼çµ¦å‡ºã€Œè·Œç ´èµ·æ¼²é»æˆ–150æ—¥ç·šã€çš„æŠ€è¡“é¢é˜²å®ˆç·šã€‚
3. è¿½åƒ¹éƒ¨éšŠï¼šé€™æ³¢æ³•äººç‹‚è²·æ˜¯çœŸå¤–è³‡é‚„æ˜¯éš”æ—¥æ²–ï¼Ÿè©•ä¼°å¸‚å ´æ˜¯å¦éç†±ï¼Œçµ¦å‡ºç§»å‹•åœåˆ©é˜²å®ˆåƒ¹ä½ã€‚
"""
    prompt_path = project_root / "data" / "temp" / "daily_gemini_prompt.txt"
    with open(prompt_path, "w", encoding="utf-8") as f:
        f.write(prompt_content)
    print(f"\nğŸ¤– é«˜ç››ç´š AI æ·±åº¦ç ”ç©¶ Prompt å·²è‡ªå‹•ç”Ÿæˆä¸¦å®Œæˆç›®æ¨™èšç„¦ï¼š{prompt_path}")


if __name__ == "__main__":
    generate_explosive_master_table()