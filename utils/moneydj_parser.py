import requests
from bs4 import BeautifulSoup
import time
import random
import os
import urllib3
import re
from pathlib import Path
from dotenv import load_dotenv

# 1. å¿½ç•¥ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# 2. è¼‰å…¥ .env
project_root = Path(__file__).resolve().parent.parent
env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(env_path)


class MoneyDJParser:
    BASE_URL = "https://concords.moneydj.com/z/zc"
    HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://concords.moneydj.com/'
    }

    # === ä¸­è‹±æ–‡æ¬„ä½å°ç…§è¡¨ (Data Dictionary) ===
    FIELD_MAP = {
        "quarter": "å­£åˆ¥",
        "year": "å¹´åº¦",
        "month": "æœˆä»½",
        "gross_margin": "æ¯›åˆ©ç‡(%)",
        "op_margin": "ç‡Ÿç›Šç‡(%)",
        "net_pre_tax": "ç¨…å‰æ·¨åˆ©(ç™¾è¬)",
        "net_after_tax": "ç¨…å¾Œæ·¨åˆ©(ç™¾è¬)",
        "eps": "EPS(å…ƒ)",
        "eps_yearly": "å¹´åº¦EPS(å…ƒ)",
        "inventory": "å­˜è²¨(ç™¾è¬)",
        "contract_liab": "åˆç´„è² å‚µ(æµå‹•)(ç™¾è¬)",
        "rev_yoy": "æœˆç‡Ÿæ”¶å¹´å¢ç‡(%)",
        "rev_cum_yoy": "æœˆç‡Ÿæ”¶ç´¯è¨ˆå¹´å¢ç‡(%)",
        "op_cash_flow": "ä¾†è‡ªç‡Ÿé‹ä¹‹ç¾é‡‘æµé‡(ç™¾è¬)",
        "foreign_hold_pct": "å¤–è³‡æŒè‚¡æ¯”ä¾‹(%)",
        "invest_trust_hold_pct": "æŠ•ä¿¡æŒè‚¡æ¯”ä¾‹(%)",
        "dealer_hold_pct": "è‡ªç‡Ÿå•†æŒè‚¡æ¯”ä¾‹(%)",
        "margin_balance_pct": "èè³‡é¤˜é¡æ¯”ä¾‹(%)",
        "short_balance_pct": "èåˆ¸é¤˜é¡æ¯”ä¾‹(%)",
        "total_legal_pct": "ä¸‰å¤§æ³•äººåˆè¨ˆæ¯”ä¾‹(%)"
    }

    def __init__(self, sid):
        self.sid = str(sid).strip()
        self.proxies = None
        http_proxy = os.getenv("HTTP_PROXY")
        https_proxy = os.getenv("HTTPS_PROXY")
        if http_proxy or https_proxy:
            self.proxies = {"http": http_proxy, "https": https_proxy}

    def _get_soup(self, url):
        """ é€šç”¨è«‹æ±‚å‡½å¼ï¼Œå›å‚³ Soup """
        try:
            time.sleep(random.uniform(0.6, 1.5))
            res = requests.get(url, headers=self.HEADERS, proxies=self.proxies, timeout=15, verify=False)
            res.encoding = 'big5'  # MoneyDJ å›ºå®šç·¨ç¢¼

            if res.status_code != 200:
                print(f"âš ï¸ Status {res.status_code} for {url}")
                return None
            return BeautifulSoup(res.text, 'html.parser')
        except Exception as e:
            print(f"âŒ Exception for {url}: {e}")
            return None

    def _clean_val(self, val_str):
        """ æ¸…æ´—æ•¸å€¼ï¼šç§»é™¤é€—è™Ÿã€ç™¾åˆ†æ¯”ã€ç©ºç™½ï¼Œè½‰ç‚º float """
        if not val_str: return 0.0
        val_str = str(val_str).strip().replace(',', '').replace('%', '')
        if val_str in ['-', '', 'N/A', 'nan']:
            return 0.0
        try:
            return float(val_str)
        except:
            return 0.0

    # ==========================================
    # 1. ç²åˆ©èƒ½åŠ› (å­£å ±) - ZCE (å·²ä¿®æ­£)
    # é‚è¼¯ï¼šæ¯ä¸€åˆ—æ˜¯ä¸€å€‹å­£åº¦ï¼Œç¬¬0æ¬„æ˜¯å­£åˆ¥
    # ==========================================
    def get_profitability_quarterly(self, limit=4):
        url = f"{self.BASE_URL}/zce/zce_{self.sid}.djhtm"
        soup = self._get_soup(url)
        if not soup: return []

        table = soup.find("table", id="oMainTable")
        if not table: return []

        results = []
        rows = table.find_all("tr")

        for tr in rows:
            tds = tr.find_all("td")
            # MoneyDJ ZCE æ¨™æº–è¡¨æ ¼é€šå¸¸æœ‰ 11 æ¬„
            # 0:å­£åˆ¥, 4:æ¯›åˆ©ç‡, 6:ç‡Ÿç›Šç‡, 8:ç¨…å‰, 9:ç¨…å¾Œ, 10:EPS
            if len(tds) >= 11:
                quarter = tds[0].get_text(strip=True)

                # æª¢æŸ¥æ˜¯å¦ç‚ºå­£åˆ¥æ ¼å¼ (ä¾‹å¦‚ 114.3Q)
                if '.' in quarter and 'Q' in quarter:
                    item = {
                        "quarter": quarter,
                        "gross_margin": self._clean_val(tds[4].get_text()),
                        "op_margin": self._clean_val(tds[6].get_text()),
                        "net_pre_tax": self._clean_val(tds[8].get_text()),
                        "net_after_tax": self._clean_val(tds[9].get_text()),
                        "eps": self._clean_val(tds[10].get_text())
                    }
                    results.append(item)
                    if len(results) >= limit: break
        return results

    # ==========================================
    # 2. ç¶“ç‡Ÿç¸¾æ•ˆ (å¹´å ±) - ZCDJ
    # æŠ“å–ï¼šæœ€æ–°3å€‹å¹´åº¦çš„ç¨…å¾Œæ¯è‚¡ç›ˆé¤˜(å…ƒ)
    # ==========================================
    def get_yearly_performance(self, limit=3):
        url = f"{self.BASE_URL}/zcdj/zcdj_{self.sid}.djhtm"
        soup = self._get_soup(url)
        if not soup: return []

        table = soup.find("table", id="oMainTable")
        if not table: return []

        results = []
        rows = table.find_all("tr")

        # å…ˆæ‰¾å‡º EPS åœ¨ç¬¬å¹¾æ¬„ (å› ç‚ºå¹´å ±æ¬„ä½è¼ƒå¤šï¼Œå¯èƒ½æœ‰è®Šå‹•)
        eps_index = -1

        # æ¨™é¡Œåˆ—é€šå¸¸åœ¨ id="oScrollMenu"
        header_row = soup.find("tr", id="oScrollMenu")
        if not header_row and len(rows) > 0:
            header_row = rows[0]

        if header_row:
            for i, td in enumerate(header_row.find_all("td")):
                txt = td.get_text(strip=True)
                if "ç¨…å¾Œ" in txt and "ç›ˆé¤˜" in txt:
                    eps_index = i
                    break

        if eps_index == -1: return []

        for tr in rows[1:]:  # è·³éæ¨™é¡Œ
            tds = tr.find_all("td")
            if len(tds) > eps_index:
                year_str = tds[0].get_text(strip=True)
                if year_str.isdigit() and len(year_str) <= 3:  # ç¢ºä¿ç¬¬ä¸€æ¬„æ˜¯å¹´åº¦ (ex: 113)
                    results.append({
                        "year": year_str,
                        "eps_yearly": self._clean_val(tds[eps_index].get_text())
                    })
                    if len(results) >= limit: break
        return results

    # ==========================================
    # 3. è³‡ç”¢è² å‚µè¡¨ - ZCPA (çŸ©é™£å¼)
    # æŠ“å–ï¼šå­˜è²¨ã€åˆç´„è² å‚µï¼æµå‹•
    # ==========================================
    def get_balance_sheet(self, limit=5):
        url = f"{self.BASE_URL}/zcp/zcpa/zcpa_{self.sid}.djhtm"
        soup = self._get_soup(url)
        if not soup: return []

        table = soup.find("table", id="oMainTable")
        if not table: return []

        rows = soup.find_all("div", class_="table-row")  # MoneyDJ ç‰¹æ®Š div è¡¨æ ¼
        if not rows: return []

        quarters = []
        # ç¬¬ä¸€åˆ—æ˜¯æœŸåˆ¥
        q_row_cells = rows[0].find_all("span", class_="table-cell")
        for cell in q_row_cells[1:]:
            quarters.append(cell.get_text(strip=True))

        inventories = []
        contract_liabs = []

        # é è¨­å€¼
        if not inventories: inventories = [0] * len(quarters)
        if not contract_liabs: contract_liabs = [0] * len(quarters)

        for row in rows:
            cells = row.find_all("span", class_="table-cell")
            if not cells: continue

            title = cells[0].get_text(strip=True)

            if title == "å­˜è²¨":  # ç²¾ç¢ºæ¯”å°
                inventories = [self._clean_val(c.get_text()) for c in cells[1:]]

            if "åˆç´„è² å‚µ" in title and "æµå‹•" in title and "é" not in title:
                contract_liabs = [self._clean_val(c.get_text()) for c in cells[1:]]
            elif title == "åˆç´„è² å‚µ" and all(v == 0 for v in contract_liabs):  # å‚™ç”¨
                contract_liabs = [self._clean_val(c.get_text()) for c in cells[1:]]

        results = []
        count = min(len(quarters), limit)
        for i in range(count):
            results.append({
                "quarter": quarters[i],
                "inventory": inventories[i] if i < len(inventories) else 0,
                "contract_liab": contract_liabs[i] if i < len(contract_liabs) else 0
            })
        return results

    # ==========================================
    # 4. æœˆç‡Ÿæ”¶ - ZCH
    # æŠ“å–ï¼šå»å¹´åŒæœŸå¹´å¢ç‡ã€ç´¯è¨ˆå¹´å¢ç‡
    # ==========================================
    def get_monthly_revenue(self, limit=6):
        url = f"{self.BASE_URL}/zch/zch_{self.sid}.djhtm"
        soup = self._get_soup(url)
        if not soup: return []

        rows = soup.find_all("tr")
        results = []

        for tr in rows:
            tds = tr.find_all("td")
            if len(tds) >= 7:
                date_str = tds[0].get_text(strip=True)
                # é©—è­‰æ—¥æœŸæ ¼å¼ 114/01
                if '/' in date_str and len(date_str) >= 5 and date_str[0].isdigit():
                    try:
                        # æ’é™¤æ¨™é¡Œåˆ— (æ¨™é¡Œä¸æœƒæ˜¯æ•¸å­—é–‹é ­)
                        yoy = self._clean_val(tds[4].get_text())
                        cum_yoy = self._clean_val(tds[6].get_text())

                        results.append({
                            "month": date_str,
                            "rev_yoy": yoy,
                            "rev_cum_yoy": cum_yoy
                        })
                    except:
                        continue
                    if len(results) >= limit: break
        return results

    # ==========================================
    # 5. ç¾é‡‘æµé‡è¡¨ - ZC3 (çŸ©é™£å¼)
    # æŠ“å–ï¼šä¾†è‡ªç‡Ÿé‹ä¹‹ç¾é‡‘æµé‡
    # ==========================================
    def get_cash_flow(self, limit=5):
        url = f"{self.BASE_URL}/zc3/zc3_{self.sid}.djhtm"
        soup = self._get_soup(url)
        if not soup: return []

        rows = soup.find_all("div", class_="table-row")
        if not rows: return []

        quarters = []
        q_row_cells = rows[0].find_all("span", class_="table-cell")
        for cell in q_row_cells[1:]:
            quarters.append(cell.get_text(strip=True))

        op_cash = [0] * len(quarters)

        for row in rows:
            cells = row.find_all("span", class_="table-cell")
            if not cells: continue
            title = cells[0].get_text(strip=True)

            if "ä¾†è‡ªç‡Ÿé‹" in title and "ç¾é‡‘æµé‡" in title:
                op_cash = [self._clean_val(c.get_text()) for c in cells[1:]]
                break

        results = []
        count = min(len(quarters), limit)
        for i in range(count):
            results.append({
                "quarter": quarters[i],
                "op_cash_flow": op_cash[i] if i < len(op_cash) else 0
            })
        return results

    # ==========================================
    # 6. ç±Œç¢¼åˆ†ä½ˆ (è§£æ zcj é é¢) - 2026/02/25 å„ªåŒ–ç‰ˆ
    # ==========================================
    def get_chips_distribution(self):
        url = f"{self.BASE_URL}/zcj/zcj_{self.sid}.djhtm"
        soup = self._get_soup(url)
        if not soup: return {}

        data = {}

        # --- 1. æŠ“å–è³‡æ–™æ—¥æœŸ (æ¨™è¨˜è³‡æ–™å®šéŒ¨é») ---
        # çµæ§‹: <div class="t11">æ—¥æœŸï¼š02/24</div>
        date_div = soup.find("div", class_="t11")
        if date_div:
            date_text = date_div.get_text(strip=True)
            # å–å¾— "02/24"
            data["data_date"] = date_text.replace("æ—¥æœŸï¼š", "")

        # --- 2. è§£æè¡¨æ ¼è³‡æ–™ ---
        # æ¨™ç±¤ç‰¹å¾µ: åç¨±åœ¨ td[0], æ¯”ä¾‹åœ¨ td[3]
        target_map = {
            "å¤–è³‡æŒè‚¡": "foreign_hold_pct",
            "æŠ•ä¿¡æŒè‚¡": "invest_trust_hold_pct",
            "è‡ªç‡Ÿå•†æŒè‚¡": "dealer_hold_pct",
            "èè³‡é¤˜é¡": "margin_balance_pct",
            "èåˆ¸é¤˜é¡": "short_balance_pct"
        }

        # éæ­·æ‰€æœ‰ trï¼Œä¸è«–å¤§å°å¯«
        for tr in soup.find_all(re.compile('^tr$', re.I)):
            tds = tr.find_all(re.compile('^td$', re.I))
            if len(tds) >= 4:
                # å–å¾—åç¨±ä¸¦æ¸…æ´—ç©ºç™½èˆ‡ç‰¹æ®Šå­—å…ƒ
                name = tds[0].get_text(strip=True).replace('\xa0', '')

                if name in target_map:
                    # æ¯”ä¾‹å›ºå®šåœ¨ç¬¬å››å€‹ td (Index 3)
                    val_str = tds[3].get_text(strip=True)
                    data[target_map[name]] = self._clean_val(val_str)

        # --- 3. æ‰‹å‹•åŠ ç¸½ä¸‰å¤§æ³•äººåˆè¨ˆ (ç‚ºäº†å¤§è¡¨å‘ˆç¾) ---
        legal_list = ["foreign_hold_pct", "invest_trust_hold_pct", "dealer_hold_pct"]
        if any(key in data for key in legal_list):
            total = sum(data.get(key, 0.0) for key in legal_list)
            data["total_legal_pct"] = round(total, 2)

        return data


    # ==========================================
    # æ•´åˆåŸ·è¡Œ
    # ==========================================
    def get_full_analysis(self):
        return {
            "sid": self.sid,
            "last_updated": time.strftime("%Y-%m-%d %H:%M:%S"),
            "profitability": self.get_profitability_quarterly(),
            "yearly_perf": self.get_yearly_performance(),
            "balance_sheet": self.get_balance_sheet(),
            "revenue": self.get_monthly_revenue(),
            "cash_flow": self.get_cash_flow(),
            "chips": self.get_chips_distribution()
        }


if __name__ == "__main__":
    # æœ¬æ©Ÿæ¸¬è©¦
    test_sid = "3665"
    print(f"ğŸš€ [Test] æ¸¬è©¦ MoneyDJ çˆ¬èŸ² (BeautifulSoup ç‰ˆ): {test_sid} ...")

    parser = MoneyDJParser(test_sid)

    print("\n--- 1. ç²åˆ©èƒ½åŠ› (å­£å ±) ---")
    print(parser.get_profitability_quarterly())

    print("\n--- 2. ç¶“ç‡Ÿç¸¾æ•ˆ (å¹´å ± EPS) ---")
    print(parser.get_yearly_performance())

    print("\n--- 3. è³‡ç”¢è² å‚µ (å­˜è²¨/åˆç´„è² å‚µ) ---")
    print(parser.get_balance_sheet())

    print("\n--- 4. æœˆç‡Ÿæ”¶ (YoY) ---")
    print(parser.get_monthly_revenue())

    print("\n--- 5. ç¾é‡‘æµé‡ (ç‡Ÿé‹) ---")
    print(parser.get_cash_flow())

    print("\n--- 6. ç±Œç¢¼åˆ†ä½ˆ (ä½”æ¯”) ---")
    print(parser.get_chips_distribution())

    print("\nâœ… æ¸¬è©¦å®Œæˆ")