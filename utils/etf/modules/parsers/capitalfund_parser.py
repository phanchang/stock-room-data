# utils/etf/modules/parsers/capitalfund_parser.py
import pandas as pd
import json
from pathlib import Path


class CapitalFundParser:
    def __init__(self, raw_dir, clean_dir, etf_code="00982A"):
        self.raw_dir = Path(raw_dir)
        self.clean_dir = Path(clean_dir)
        self.etf_code = etf_code
        self.out_file = self.clean_dir / f"{etf_code}.csv"

    def parse_json(self, file_path: Path) -> pd.DataFrame:
        """è§£æå–®å€‹ JSONï¼Œå›å‚³æ¨™æº–æ¬„ä½ DataFrame"""
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        stocks = data.get("data", {}).get("stocks", [])
        if not stocks:
            return pd.DataFrame()

        df = pd.DataFrame(stocks)

        # 1. ç¯©é¸èˆ‡é‡æ–°å‘½åæ¬„ä½
        col_map = {
            "stocNo": "stock_code",
            "stocName": "stock_name",
            "share": "shares",
            "weight": "weight"
        }
        df = df[list(col_map.keys()) + ["date1"]].rename(columns=col_map)

        # 2. è™•ç†æ—¥æœŸ ("2026/2/11 ä¸Šåˆ 12:00:00" -> "2026-02-11")
        # æ‹†åˆ†å­—ä¸²ï¼Œåªå–å‰é¢æ—¥æœŸçš„éƒ¨åˆ†ï¼Œç„¶å¾Œè½‰ç‚º YYYY-MM-DD
        df["date"] = df["date1"].apply(lambda x: pd.to_datetime(str(x).split(' ')[0]).strftime("%Y-%m-%d"))

        # âœ¨ æ–°å¢ï¼šæ—¥æœŸæ ¡é©—é˜²å‘†
        # æª¢æŸ¥ JSON å…§å®¹æ—¥æœŸ (2026-02-11 -> 20260211) æ˜¯å¦èˆ‡æª”å (20260211) ä¸€è‡´
        internal_date = df["date"].iloc[0].replace('-', '')
        file_date = file_path.stem
        if internal_date != file_date:
            print(f"âš ï¸  æ’é™¤é‡è¤‡è³‡æ–™: {file_path.name} (å…§å®¹æ—¥æœŸ {df['date'].iloc[0]} èˆ‡æª”åä¸ç¬¦)")
            return pd.DataFrame()

        df = df.drop(columns=["date1"])

        # 3. ç¢ºä¿å‹åˆ¥æ­£ç¢º
        df["shares"] = df["shares"].astype(float).astype(int)  # æœ‰äº› JSON æœƒæ˜¯ 1445000.0ï¼Œå…ˆè½‰æµ®é»å†è½‰æ•´æ•¸
        df["weight"] = df["weight"].astype(float)

        return df

    def parse_all_files(self):
        """è§£æç›®éŒ„ä¸‹æ‰€æœ‰ JSON ä¸¦åˆä½µè¼¸å‡º CSV"""
        if not self.raw_dir.exists():
            print(f"âš ï¸ RAW_DIR ä¸å­˜åœ¨ï¼š{self.raw_dir}")
            return

        files = sorted(self.raw_dir.rglob("*.json"))
        if not files:
            print(f"âš ï¸ æ‰¾ä¸åˆ° JSON æª”æ¡ˆï¼š{self.raw_dir}")
            return

        print(f"ğŸ“‚ æ‰¾åˆ° {len(files)} å€‹ JSONï¼Œé–‹å§‹è§£æ {self.etf_code} ...")

        all_rows = []
        for f in files:
            try:
                df = self.parse_json(f)
                if not df.empty:
                    all_rows.append(df)
            except Exception as e:
                print(f"âš ï¸ è§£æå¤±æ•—ï¼š{f.name} ({e})")

        if not all_rows:
            print("âŒ æ²’æœ‰è§£æå‡ºä»»ä½•æœ‰æ•ˆè³‡æ–™")
            return

        # åˆä½µè³‡æ–™
        result = pd.concat(all_rows, ignore_index=True)

        # âœ¨ æ–°å¢ï¼šå…¨åŸŸå»é‡é˜²å‘†
        result = result.drop_duplicates(subset=['stock_code', 'date'], keep='last')

        # æ’åºèˆ‡è¼¸å‡º
        result = result.sort_values(by=["date", "weight"], ascending=[True, False])

        self.out_file.parent.mkdir(parents=True, exist_ok=True)
        result.to_csv(self.out_file, index=False, encoding="utf-8-sig")
        print(f"âœ… è§£æå®Œæˆï¼Œè¼¸å‡ºåˆ°ï¼š{self.out_file}")