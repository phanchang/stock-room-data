"""
StockWarRoom æ ¸å¿ƒæ•¸æ“šæ•´åˆå™¨ V12.2 - è³‡åˆ¸çŸ©é™£ç²¾æº–ç‰ˆ
åŸºæ–¼ V12.0 (User Verified) é€²è¡Œæ“´å……ï¼š
1. [è³‡åˆ¸] å‡ç´šç‚º 25æ—¥ æ­·å²çŸ©é™£ï¼Œä»¥è¨ˆç®— 5/10/20 æ—¥ç´¯è¨ˆã€‚
2. [æ ¡æ­£] ä¸Šæ«ƒè³‡åˆ¸é‚è¼¯åš´æ ¼éµå®ˆ Schemaï¼šèè³‡(6-2), èåˆ¸(14-10)ã€‚
3. [é˜²è­·] åŠ å…¥è«‹æ±‚å»¶é²ï¼Œé¿å… 307 å°é–ã€‚
"""

import pandas as pd
import requests
from pathlib import Path
import urllib3
import os
import time
import random
from datetime import datetime, timedelta
from dotenv import load_dotenv

# åˆå§‹åŒ–
load_dotenv()
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å¸¸æ•¸è¨­å®š
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36', 'Referer': 'https://www.twse.com.tw/'}
PROXIES = {'http': os.getenv("HTTP_PROXY"), 'https': os.getenv("HTTPS_PROXY")} if os.getenv("HTTP_PROXY") else None

def get_trading_days(n=25):
    days, offset = [], 0
    while len(days) < n and offset < 60:
        dt = datetime.now() - timedelta(days=offset)
        if dt.weekday() < 5: days.append(dt)
        offset += 1
    return days

def get_roc_date(dt):
    # ä¿®æ­£: é…åˆçŸ©é™£è¿´åœˆï¼Œç›´æ¥å‚³å…¥ datetime ç‰©ä»¶è½‰æ›
    return f"{dt.year-1911}/{dt.month:02d}/{dt.day:02d}"

def parse_val(v):
    try:
        if isinstance(v, (int, float)): return float(v)
        v = str(v).strip().replace(',', '')
        return 0.0 if v in ['-', '', 'N/A', 'null'] else float(v)
    except: return 0.0

def get_streak(series):
    """è¨ˆç®—é€£è²·/é€£è³£"""
    vals = series.values
    if len(vals) == 0 or vals[0] == 0: return 0
    count, is_buying = 0, (vals[0] > 0)
    for v in vals:
        if (is_buying and v > 0): count += 1
        elif (not is_buying and v < 0): count -= 1
        else: break
    return count

# ==========================================
# 1. ç±Œç¢¼é¢ (Chips) - V12.0 åŸå°ä¸å‹•
# ==========================================
def fetch_chips_matrix():
    print(f"ğŸ“¡ [1/4] æŠ“å–æ³•äººç±Œç¢¼ (é€£è²·æ ¡æº–æ¨¡å¼)...")
    days = get_trading_days(25)
    t_hist, f_hist = {}, {}

    for dt in days:
        d_str = dt.strftime('%Y%m%d')
        # é…åˆ V12 é‚è¼¯çš„æ—¥æœŸæ ¼å¼
        d_roc = f"{dt.year-1911}/{dt.month:02d}/{dt.day:02d}"

        day_df = pd.DataFrame()

        # ç‚ºäº†å®‰å…¨ï¼Œç¨å¾®ä¼‘æ¯ä¸€ä¸‹
        time.sleep(random.uniform(1.0, 2.0))

        # ä¸Šå¸‚
        try:
            res = requests.get(f"https://www.twse.com.tw/rwd/zh/fund/T86?date={d_str}&selectType=ALL&response=json", headers=HEADERS, proxies=PROXIES, timeout=15, verify=False).json()
            if res.get('stat') == 'OK':
                df = pd.DataFrame(res['data'], columns=res['fields'])
                idx_f = next(i for i, f in enumerate(res['fields']) if 'å¤–é™¸è³‡' in f and 'è²·è³£è¶…' in f)
                idx_t = next(i for i, f in enumerate(res['fields']) if 'æŠ•ä¿¡' in f and 'è²·è³£è¶…' in f)
                day_df = pd.concat([day_df, df.iloc[:, [0, idx_f, idx_t]].rename(columns={df.columns[0]:'sid', df.columns[idx_f]:'f', df.columns[idx_t]:'t'})])
        except: pass
        # ä¸Šæ«ƒ
        try:
            res = requests.get(f"https://www.tpex.org.tw/web/stock/3insti/daily_trade/3itrade_hedge_result.php?l=zh-tw&o=json&se=EW&t=D&d={d_roc}", headers=HEADERS, proxies=PROXIES, timeout=30, verify=False).json()
            raw = res['tables'][0]['data'] if 'tables' in res else res.get('aaData', [])
            if raw:
                df = pd.DataFrame(raw).iloc[:, [0, 4, 13]]
                df.columns = ['sid', 'f', 't']
                day_df = pd.concat([day_df, df])
        except: pass

        if not day_df.empty:
            day_df['sid'] = day_df['sid'].str.strip()
            t_hist[d_str] = day_df.set_index('sid')['t'].apply(parse_val) // 1000
            f_hist[d_str] = day_df.set_index('sid')['f'].apply(parse_val) // 1000
            print(".", end="", flush=True)

    print(" Done.")
    t_m, f_m = pd.DataFrame(t_hist).fillna(0), pd.DataFrame(f_hist).fillna(0)
    dates = sorted(t_m.columns, reverse=True)
    res = pd.DataFrame(index=t_m.index)
    res['t_net_today'], res['t_sum_5d'], res['t_sum_20d'] = t_m[dates[0]], t_m[dates[:5]].sum(axis=1), t_m[dates[:20]].sum(axis=1)
    res['f_net_today'], res['f_sum_5d'], res['f_sum_20d'] = f_m[dates[0]], f_m[dates[:5]].sum(axis=1), f_m[dates[:20]].sum(axis=1)
    res['t_streak'], res['f_streak'] = t_m[dates].apply(get_streak, axis=1), f_m[dates].apply(get_streak, axis=1)
    return res

# ==========================================
# 2. èè³‡èåˆ¸ (Margin) - å‡ç´šçŸ©é™£æ¨¡å¼
# ==========================================
def fetch_margin_matrix():
    print("ğŸ“¡ [2/4] æŠ“å–è³‡åˆ¸è®ŠåŒ– (æ­·å²å›æº¯çŸ©é™£)...")
    days = get_trading_days(25)
    m_hist, s_hist = {}, {}

    for dt in days:
        d_str = dt.strftime('%Y%m%d')
        d_roc = f"{dt.year-1911}/{dt.month:02d}/{dt.day:02d}"
        day_df = pd.DataFrame()

        # [å®‰å…¨ä¿è­·] é¿å…é€£çºŒè«‹æ±‚å°è‡´ 307ï¼Œå¼·åˆ¶ä¼‘æ¯
        time.sleep(random.uniform(2.0, 3.0))

        # ä¸Šå¸‚ (TWSE)
        try:
            url = f"https://www.twse.com.tw/rwd/zh/marginTrading/MI_MARGN?date={d_str}&selectType=ALL&response=json"
            res = requests.get(url, headers=HEADERS, proxies=PROXIES, timeout=15, verify=False).json()
            if res.get('stat') == 'OK':
                target = next((t for t in res.get('tables', []) if len(t.get('fields', [])) == 16), None)
                if target:
                    temp = []
                    for r in target['data']:
                        # V12 é‚è¼¯: 6(ä»Š)-5(æ˜¨), 12(ä»Š)-11(æ˜¨)
                        m_diff = parse_val(r[6]) - parse_val(r[5])
                        s_diff = parse_val(r[12]) - parse_val(r[11])
                        temp.append({'sid': r[0].strip(), 'm': int(m_diff), 's': int(s_diff)})
                    day_df = pd.concat([day_df, pd.DataFrame(temp)])
        except: pass

        # ä¸Šæ«ƒ (TPEx) - [é—œéµä¿®æ­£] ä½¿ç”¨æ‚¨æä¾›çš„æ­£ç¢º Schema ç´¢å¼•
        try:
            url = f"https://www.tpex.org.tw/web/stock/margin_trading/margin_balance/margin_bal_result.php?l=zh-tw&o=json&se=EW&d={d_roc}&t=D"
            res = requests.get(url, headers=HEADERS, proxies=PROXIES, timeout=15, verify=False).json()
            raw = res['tables'][0]['data'] if 'tables' in res else res.get('aaData', [])
            if raw:
                temp = []
                for r in raw:
                    # ä¾æ“š Schema: [2]å‰è³‡, [6]è³‡é¤˜é¡ => 6-2
                    m_diff = parse_val(r[6]) - parse_val(r[2])
                    # ä¾æ“š Schema: [10]å‰åˆ¸, [14]åˆ¸é¤˜é¡ => 14-10
                    s_diff = parse_val(r[14]) - parse_val(r[10])
                    temp.append({'sid': r[0].strip(), 'm': int(m_diff), 's': int(s_diff)})
                day_df = pd.concat([day_df, pd.DataFrame(temp)])
        except: pass

        if not day_df.empty:
            m_hist[d_str] = day_df.set_index('sid')['m']
            s_hist[d_str] = day_df.set_index('sid')['s']
            print(".", end="", flush=True)
        else:
            print("x", end="", flush=True)

    print(" Done.")

    # å»ºç«‹ DataFrame ä¸¦è¨ˆç®—ç´¯è¨ˆ
    m_m, s_m = pd.DataFrame(m_hist).fillna(0), pd.DataFrame(s_hist).fillna(0)
    if m_m.empty: return pd.DataFrame()

    dates = sorted(m_m.columns, reverse=True)
    res = pd.DataFrame(index=m_m.index)

    # é€™è£¡åŠ å…¥æ‚¨è¦çš„ 1æ—¥/5æ—¥/10æ—¥/20æ—¥
    res['m_net_today'] = m_m[dates[0]]
    res['m_sum_5d'] = m_m[dates[:5]].sum(axis=1)
    res['m_sum_10d'] = m_m[dates[:10]].sum(axis=1) # æ–°å¢
    res['m_sum_20d'] = m_m[dates[:20]].sum(axis=1)

    res['s_net_today'] = s_m[dates[0]]
    res['s_sum_5d'] = s_m[dates[:5]].sum(axis=1)
    res['s_sum_10d'] = s_m[dates[:10]].sum(axis=1) # æ–°å¢
    res['s_sum_20d'] = s_m[dates[:20]].sum(axis=1)

    return res

# ==========================================
# 3. ç‡Ÿæ”¶ (Revenue) - V12.0 åŸå°ä¸å‹•
# ==========================================
def fetch_revenue():
    print("ğŸ“¡ [3/4] æŠ“å–æœˆç‡Ÿæ”¶...")
    rs = []
    for url in ["https://openapi.twse.com.tw/v1/opendata/t187ap05_L", "https://www.tpex.org.tw/openapi/v1/mopsfin_t187ap05_O"]:
        try:
            df = pd.DataFrame(requests.get(url, proxies=PROXIES, timeout=20, verify=False).json())
            df.columns = [c.replace('ç‡Ÿæ¥­æ”¶å…¥-', '') for c in df.columns]
            df = df.rename(columns={'å…¬å¸ä»£è™Ÿ':'sid', 'å…¬å¸åç¨±':'name', 'ç”¢æ¥­åˆ¥':'industry', 'å»å¹´åŒæœˆå¢æ¸›(%)':'rev_yoy', 'ç•¶æœˆç‡Ÿæ”¶':'rev_now', 'è³‡æ–™å¹´æœˆ':'rev_ym'})
            rs.append(df[['sid', 'name', 'industry', 'rev_ym', 'rev_yoy', 'rev_now']])
        except: pass
    return pd.concat(rs).set_index('sid') if rs else pd.DataFrame()

# ==========================================
# 4. ä¼°å€¼ (Valuation) - V12.0 åŸå°ä¸å‹•
# ==========================================
def fetch_valuation():
    print("ğŸ“¡ [4/4] æŠ“å–ä¼°å€¼ (PE/PB/Yield)...")
    vd = []
    try: # ä¸Šå¸‚
        res = requests.get("https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d?selectType=ALL&response=json", headers=HEADERS, proxies=PROXIES, verify=False).json()
        f = res['fields']
        ipe, iy, ipb = f.index("æœ¬ç›Šæ¯”"), f.index("æ®–åˆ©ç‡(%)"), f.index("è‚¡åƒ¹æ·¨å€¼æ¯”")
        for r in res['data']: vd.append({'sid': r[0].strip(), 'pe': parse_val(r[ipe]), 'yield': parse_val(r[iy]), 'pbr': parse_val(r[ipb])})
    except: pass
    for offset in [0, 1]: # ä¸Šæ«ƒ
        dt = datetime.now() - timedelta(days=offset)
        d_roc = f"{dt.year-1911}/{dt.month:02d}/{dt.day:02d}"
        try:
            res = requests.get(f"https://www.tpex.org.tw/web/stock/aftertrading/peratio_analysis/pera_result.php?l=zh-tw&o=json&d={d_roc}", headers=HEADERS, proxies=PROXIES, verify=False).json()
            raw = res['tables'][0]['data'] if 'tables' in res else res.get('aaData', [])
            if raw:
                for r in raw: vd.append({'sid': r[0].strip(), 'pe': parse_val(r[2]), 'yield': parse_val(r[5]), 'pbr': parse_val(r[6])})
                break
        except: continue
    return pd.DataFrame(vd).set_index('sid')

# ==========================================
# ä¸»ç¨‹å¼
# ==========================================
def main():
    p = Path(__file__).resolve().parent.parent / "data" / "temp" / "chips_revenue_raw.csv"
    p.parent.mkdir(parents=True, exist_ok=True)

    # æ”¹ç”¨ fetch_margin_matrix
    rev, chips, margin, val = fetch_revenue(), fetch_chips_matrix(), fetch_margin_matrix(), fetch_valuation()

    print("\nğŸ”„ æ•¸æ“šå¤§åˆé«”...")
    final = rev.join([chips, margin, val], how='left').fillna(0)

    final.to_csv(p, encoding='utf-8-sig')
    print(f"\nâœ¨ V12.2 æˆ°æƒ…å®¤æ•¸æ“šå°±ç·’ï¼\nä½ç½®: {p}")

    if '2330' in final.index:
         print(f"ğŸ“Š 2330 è³‡: {final.loc['2330'][['m_net_today', 'm_sum_5d']].to_dict()}")

if __name__ == "__main__": main()