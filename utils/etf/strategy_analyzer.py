import pandas as pd
import numpy as np
from pathlib import Path
import sys
from datetime import datetime

# ==================================================
# 1. å°ˆæ¡ˆè·¯å¾‘åˆå§‹åŒ–
# ==================================================
current_file = Path(__file__).resolve()
project_root = current_file.parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


class StrategyAnalyzer:
    """ä¸»å‹•å¼ ETF ç­–ç•¥åˆ†æå™¨ï¼šé›™æ¦œå–®ç³»çµ± (é‡é‡‘æŠ¼å¯¶æ¦œ vs æ½›ä¼å·è²·æ¦œ)"""

    def __init__(self):
        self.clean_dir = project_root / "data" / "clean"
        self.cache_dir = project_root / "data" / "cache" / "tw"
        self.all_data = []
        self.stock_market_map = {}
        self.latest_report_date = None

        self.load_market_info()

    def load_market_info(self):
        csv_path = project_root / "data" / "stock_list.csv"
        if csv_path.exists():
            try:
                for enc in ['utf-8', 'utf-8-sig', 'big5']:
                    try:
                        df = pd.read_csv(csv_path, dtype=str, encoding=enc)
                        df.columns = [c.lower().strip() for c in df.columns]
                        code_col = next((col for col in ['stock_id', 'code', 'id'] if col in df.columns), None)

                        if code_col and 'market' in df.columns:
                            for _, row in df.iterrows():
                                sid = str(row[code_col]).strip()
                                market = str(row['market']).strip().upper()
                                self.stock_market_map[sid] = market
                            break
                    except:
                        continue
            except Exception as e:
                print(f"âŒ è®€å–å¸‚å ´è³‡è¨Šå¤±æ•—: {e}")

    def get_market_suffix(self, stock_id):
        return self.stock_market_map.get(str(stock_id), "TW")

    def load_all_clean_data(self):
        print(f"ğŸ” æ­£åœ¨æƒæè³‡æ–™å¤¾: {self.clean_dir}")
        for csv_file in self.clean_dir.rglob("*.csv"):
            if csv_file.name.startswith("._") or "stock_list" in csv_file.name:
                continue
            try:
                df = pd.read_csv(csv_file)
                df['date'] = pd.to_datetime(df['date'])
                id_col = 'stock_code' if 'stock_code' in df.columns else 'stock_id'

                df = df.rename(columns={id_col: 'stock_id', 'stock_name': 'name'})
                df['stock_id'] = df['stock_id'].astype(str)
                df['etf_source'] = f"{csv_file.parent.name}_{csv_file.stem}"

                for col in ['shares', 'weight']:
                    if col in df.columns and df[col].dtype == 'object':
                        df[col] = df[col].astype(str).str.replace(',', '').str.replace('%', '')
                        df[col] = pd.to_numeric(df[col], errors='coerce')

                self.all_data.append(df)
            except Exception as e:
                pass

    def analyze_dual_leaderboards(self):
        """è¨ˆç®—é›™æ¦œå–®æ‰€éœ€çš„æ‰€æœ‰æ­·å²èˆ‡åƒ¹æ ¼ç‰¹å¾µ"""
        if not self.all_data: return pd.DataFrame()

        combined_df = pd.concat(self.all_data, ignore_index=True)
        daily_summary = combined_df.groupby(['date', 'stock_id', 'name'])['shares'].sum().reset_index()

        dates = sorted(daily_summary['date'].unique())
        if len(dates) < 5:
            print("âš ï¸ æ­·å²è³‡æ–™éå°‘ï¼Œç„¡æ³•åˆ†æã€‚")
            return pd.DataFrame()

        self.latest_report_date = dates[-1].strftime('%Y-%m-%d')

        t_now = dates[-1]
        t_5 = dates[-5] if len(dates) >= 5 else dates[0]
        t_20 = dates[-20] if len(dates) >= 20 else dates[0]
        t_60 = dates[-60] if len(dates) >= 60 else dates[0]

        analysis_results = []
        stocks = daily_summary['stock_id'].unique()

        print(f"ğŸ“ˆ å•Ÿå‹•é›™æ¦œå–®ç±Œç¢¼è¿½è¹¤å¼•æ“...")

        for stock_id in stocks:
            stock_data = daily_summary[daily_summary['stock_id'] == stock_id].sort_values('date')
            name = stock_data['name'].iloc[0]

            def get_shares(t_date):
                return stock_data[stock_data['date'] == t_date]['shares'].sum() if t_date in stock_data[
                    'date'].values else 0

            shares_now = get_shares(t_now)
            shares_5d_ago = get_shares(t_5)
            shares_20d_ago = get_shares(t_20)
            shares_60d_ago = get_shares(t_60)

            diff_5d = shares_now - shares_5d_ago
            diff_20d = shares_now - shares_20d_ago
            diff_60d = shares_now - shares_60d_ago

            # æ¢ä»¶éæ¿¾ï¼šæˆ‘å€‘åªçœ‹ã€Œè¿‘5å¤©æœ‰åœ¨è²·ã€çš„æ´»æ°´è‚¡
            if diff_5d <= 0: continue

            market = self.get_market_suffix(stock_id)
            price_path = self.cache_dir / f"{stock_id}_{market}.parquet"

            current_price = 0
            estimated_cost_60d = 0
            net_buy_value_60d = 0

            if price_path.exists():
                try:
                    price_df = pd.read_parquet(price_path)
                    price_df.columns = [c.capitalize() for c in price_df.columns]
                    price_df.index = pd.to_datetime(price_df.index).tz_localize(None)

                    if not price_df.empty:
                        current_price = price_df.iloc[-1]['Close']

                        stock_data_60 = stock_data[stock_data['date'] >= t_60].copy()
                        stock_data_60['share_change'] = stock_data_60['shares'].diff().fillna(0)

                        total_buy_cost = 0
                        total_buy_shares = 0

                        for _, row in stock_data_60.iterrows():
                            if row['share_change'] > 0:
                                p_date = row['date']
                                if p_date in price_df.index:
                                    daily_price = price_df.loc[p_date, 'Close']
                                else:
                                    nearest_idx = price_df.index.get_indexer([p_date], method='nearest')[0]
                                    daily_price = price_df.iloc[nearest_idx]['Close']

                                total_buy_cost += (row['share_change'] * daily_price)
                                total_buy_shares += row['share_change']

                        if total_buy_shares > 0:
                            estimated_cost_60d = total_buy_cost / total_buy_shares
                            net_buy_value_60d = total_buy_cost / 100000000
                except Exception:
                    pass

            analysis_results.append({
                'ä»£è™Ÿ': stock_id,
                'åç¨±': name,
                'ç•¶å‰è‚¡æ•¸': shares_now,
                '20æ—¥å‰è‚¡æ•¸': shares_20d_ago,
                'è¿‘5æ—¥å¢æ¸›': diff_5d,
                'è¿‘20æ—¥å¢æ¸›': diff_20d,
                'ä¸€å­£è€—è³‡(å„„)': round(net_buy_value_60d, 0),
                'æœ€æ–°æ”¶ç›¤åƒ¹': current_price,
                'æŠ•ä¿¡å­£æˆæœ¬': round(estimated_cost_60d, 2)
            })

        result_df = pd.DataFrame(analysis_results)
        if result_df.empty: return result_df

        result_df['ä¹–é›¢(%)'] = np.where(result_df['æŠ•ä¿¡å­£æˆæœ¬'] > 0,
                                        ((result_df['æœ€æ–°æ”¶ç›¤åƒ¹'] - result_df['æŠ•ä¿¡å­£æˆæœ¬']) / result_df[
                                            'æŠ•ä¿¡å­£æˆæœ¬'] * 100), 0)
        result_df['ä¹–é›¢(%)'] = result_df['ä¹–é›¢(%)'].round(2)

        return result_df

    def generate_ai_prompt(self, df):
            """ç”¢å‡ºé›™æ¦œå–®èˆ‡é˜²å¹»è¦ºæŸ¥è­‰æŒ‡ä»¤çš„ AI Prompt"""

            # ==========================================
            # æ¦œå–® Aï¼šé‡é‡‘æŠ¼å¯¶æ¦œ (ä¾è€—è³‡é‡‘é¡æ’åº Top 15)
            # ==========================================
            list_a = df.sort_values('ä¸€å­£è€—è³‡(å„„)', ascending=False).head(15).copy()
            list_a['ç•¶å‰è‚¡æ•¸'] = list_a['ç•¶å‰è‚¡æ•¸'].apply(lambda x: f"{x:,}")
            list_a_view = list_a[
                ['ä»£è™Ÿ', 'åç¨±', 'ç•¶å‰è‚¡æ•¸', 'è¿‘5æ—¥å¢æ¸›', 'è¿‘20æ—¥å¢æ¸›', 'ä¸€å­£è€—è³‡(å„„)', 'æŠ•ä¿¡å­£æˆæœ¬', 'ä¹–é›¢(%)']]

            # ==========================================
            # æ¦œå–® Bï¼šæ½›ä¼å·è²·æ¦œ
            # ==========================================
            exclude_ids = list_a['ä»£è™Ÿ'].tolist()
            list_b_candidates = df[~df['ä»£è™Ÿ'].isin(exclude_ids)].copy()

            stealth_mask = (list_b_candidates['20æ—¥å‰è‚¡æ•¸'] == 0) | (
                    list_b_candidates['è¿‘5æ—¥å¢æ¸›'] == list_b_candidates['è¿‘20æ—¥å¢æ¸›'])
            list_b = list_b_candidates[stealth_mask].sort_values('è¿‘5æ—¥å¢æ¸›', ascending=False).head(15)

            list_b['ç•¶å‰è‚¡æ•¸'] = list_b['ç•¶å‰è‚¡æ•¸'].apply(lambda x: f"{x:,}")
            list_b_view = list_b[
                ['ä»£è™Ÿ', 'åç¨±', 'ç•¶å‰è‚¡æ•¸', 'è¿‘5æ—¥å¢æ¸›', 'è¿‘20æ—¥å¢æ¸›', 'ä¸€å­£è€—è³‡(å„„)', 'æŠ•ä¿¡å­£æˆæœ¬', 'ä¹–é›¢(%)']]

            # å–å¾—ç•¶å‰çœŸå¯¦å¹´ä»½èˆ‡æœˆä»½ï¼Œåšç‚ºé˜²å‘†éŒ¨é»
            current_year = pd.to_datetime(self.latest_report_date).year
            current_month = pd.to_datetime(self.latest_report_date).month

            prompt = f"""# ğŸ“… å°è‚¡ä¸»å‹•å¼ ETF ã€é›™æ¦œå–®ã€‘ç±Œç¢¼æˆ°æƒ…å ±è¡¨

    ## ğŸ“Š ç¬¬ä¸€éšæ®µï¼šé‡åŒ–æ•¸æ“šåŸºæº–
    **è³‡æ–™åº«åŸºæº–æ—¥ï¼š** {self.latest_report_date} (è«‹æ³¨æ„ç¾åœ¨çš„å¹´ä»½æ˜¯ {current_year} å¹´ {current_month} æœˆ)

    ### ğŸ† æ¦œå–® Aï¼šé‡é‡‘æŠ¼å¯¶æ¦œ (Top 15 ä¸»åŠ›è³‡é‡‘æµå‘)
    > èªªæ˜ï¼šæŠ•ä¿¡è¿‘ä¸€å­£ç ¸ä¸‹æœ€å¤šã€Œçµ•å°é‡‘é¡ã€çš„æ ¸å¿ƒæ¨™çš„ (å–®ä½ç‚ºæ–°å°å¹£ã€å„„ã€å…ƒ)ã€‚
    {list_a_view.to_markdown(index=False) if not list_a_view.empty else "ç„¡ç¬¦åˆæ¢ä»¶æ¨™çš„"}

    ### ğŸ¥· æ¦œå–® Bï¼šç ´è›‹æ½›ä¼å·è²·æ¦œ (Top 15 é›¶åˆ°ä¸€é»‘é¦¬)
    > èªªæ˜ï¼šç‰¹å¾µç‚ºã€Œéå» 20 å¤©æ²’è²·ï¼Œæœ€è¿‘çªç„¶é€£çºŒè²·é€² / å¾é›¶å»ºå€‰ã€ã€‚
    {list_b_view.to_markdown(index=False) if not list_b_view.empty else "ç„¡ç¬¦åˆæ¢ä»¶æ¨™çš„"}

    ---

    ## ğŸ¤– ç¬¬äºŒéšæ®µï¼šAI æ“ç›¤æ‰‹æ·±åº¦æ¨æ–·èˆ‡ã€å¼·åˆ¶å¤šæ–¹æŸ¥è­‰æŒ‡ä»¤ã€‘

    ä½ æ˜¯ä¸€ä½å…·å‚™ 20 å¹´ç¶“é©—çš„å°è‚¡é‡åŒ–èˆ‡åŸºæœ¬é¢æ“ç›¤æ‰‹ã€‚è«‹åŸºæ–¼ä¸Šæ–¹é›™æ¦œå–®åŸ·è¡Œåˆ†æã€‚

    âš ï¸ ã€æœ€é«˜æŒ‡å°åŸå‰‡ï¼šçµ•å°å®¢è§€èˆ‡é˜²æ™‚é–“å¹»è¦ºã€‘âš ï¸
    1. å¼•ç”¨æ•¸æ“šåšæ¨ç†èˆ‡ç ”ç©¶ã€Œå¿…é ˆã€ä½¿ç”¨ Google search é€²è¡Œå¤šæ–¹ä¾†æºäº¤å‰æŸ¥è­‰ã€‚
    2. çµ•ä¸å…è¨±è‡ªå·±ç”¢ç”Ÿã€æé€ æˆ–çŒœæ¸¬çœŸå¯¦æ•¸æ“šã€‚
    3. å¼•ç”¨ä»»ä½•æ•¸æ“šåšå‘ˆç¾æˆ–è¨ˆç®—ï¼Œå¿…é ˆåœ¨è©²æ®µè½æ˜ç¢ºé™„ä¸Šã€Œä¾†æºç¶²ç«™èˆ‡è³‡æ–™å‡ºè™•ã€ã€‚
    4. ğŸ›‘ã€æ™‚é–“é˜²å½è­¦å‘Šã€‘ï¼šç¾åœ¨æ˜¯ {current_year} å¹´ {current_month} æœˆã€‚æœå°‹æ–°èèˆ‡è²¡å ±æ™‚ï¼Œè«‹åš´æ ¼éæ¿¾æ™‚é–“ï¼**çµ•å°ç¦æ­¢**æŠŠ {current_year - 1} å¹´æˆ–æ›´æ—©çš„èˆŠæ–°èç•¶æˆç¾åœ¨çš„äº‹ä»¶ï¼

    ### ğŸ” ä»»å‹™ 1ï¼šä¸»æµæ¿å¡Š vs æ½›ä¼æ¿å¡Šå°æ¯”åˆ†æ
    * è§€å¯Ÿã€æ¦œå–® Aã€‘ï¼Œç›®å‰æŠ•ä¿¡é‡å…µé›†çµåœ¨å“ª 1~2 å€‹ç”¢æ¥­ï¼Ÿ(è¡¨å…§çš„è€—è³‡å–®ä½ç‚ºã€Œå„„ã€ï¼Œè«‹ç›´æ¥ä»¥å„„ç‚ºå–®ä½è§£è®€ï¼Œä¾‹å¦‚ 81.15 å°±æ˜¯ 81.15 å„„)
    * è§€å¯Ÿã€æ¦œå–® Bã€‘ï¼ŒæŠ•ä¿¡æ­£åœ¨å·å·ä½ˆå±€å“ªäº›ç”¢æ¥­ï¼Ÿé€™æ˜¯å¦æš—ç¤ºè³‡é‡‘æœ‰é«˜ä½ä½éšè½‰æ›çš„è·¡è±¡ï¼Ÿ

    ### ğŸ•µï¸â€â™‚ï¸ ä»»å‹™ 2ï¼šé›™æ¦œå–®æ ¸å¿ƒæ¨™çš„å®¢è§€äº‹å¯¦æŸ¥è­‰ (Fact-Checking)
    è«‹å¾ã€æ¦œå–® Aã€‘èˆ‡ã€æ¦œå–® Bã€‘å„æŒ‘é¸ 2 æª”ï¼Œ**å¼·åˆ¶ä½¿ç”¨ Google æœå°‹æŸ¥è­‰**è¿‘ä¸€å€‹æœˆå…§ ({current_year}å¹´) çš„é‡å¤§äº‹ä»¶ã€‚
    * **æ™‚é–“é˜²å‘†æª¢æŸ¥**ï¼šæ‰¾åˆ°æ–°èå¾Œï¼Œè«‹å…ˆç¢ºèªæ–°èç™¼å¸ƒå¹´ä»½æ˜¯å¦ç‚º {current_year} å¹´ã€‚å¦‚æœæ˜¯èˆŠèè«‹æ¨æ£„ã€‚
    * **æ½›ä¼è‚¡é˜²å‘†**ï¼šå°æ–¼ã€æ¦œå–® Bã€‘ï¼Œå¦‚æœä½ æŸ¥ä¸åˆ°ä»»ä½• {current_year} å¹´çš„è¿‘æœŸåˆ©å¤šæ–°èï¼Œè«‹ç›´æ¥å¯«æ˜ã€Œç¶“æŸ¥è­‰ï¼Œè¿‘æœŸç„¡ {current_year} å¹´ç›¸é—œæ–°èç™¼å¸ƒã€ã€‚ä»£è¡¨è©²è‚¡è™•æ–¼ã€Œç„¡è²å»ºå€‰æœŸã€ï¼Œçµ•å°ç¦æ­¢æ‹¿èˆŠæ–°èå¡«è£œæˆ–æé€ ï¼
    * **è¼¸å‡ºæ ¼å¼è¦æ±‚**ï¼š(ä»¥è¡¨æ ¼å‘ˆç¾)
      | æ‰€å±¬æ¦œå–® | è‚¡ç¥¨åç¨± | è¿‘æœŸçœŸå¯¦å‚¬åŒ–åŠ‘ (æŸ¥ç„¡è¿‘æœŸæ–°èè«‹èª å¯¦å¡«å¯«) | ç™¼ç”Ÿå¹´ä»½ | è³‡æ–™ä¾†æº (å¿…é ˆé™„ä¸Š URL) |

    ### ğŸ¯ ä»»å‹™ 3ï¼šæ˜æ—¥å¯¦æˆ°äº¤æ˜“æ¸…å–®æ¨æ–· (Actionable Plan)
    åŸºæ–¼æ³•äººç±Œç¢¼ç¯€å¥èˆ‡ä½ çš„å®¢è§€æŸ¥è­‰ï¼ŒæŒ‘é¸å‡º 3 æª”æœ€å€¼å¾—åˆ—å…¥æ˜æ—¥è§€å¯Ÿåå–®çš„è‚¡ç¥¨ã€‚è«‹ä¾åºæ¢åˆ—ï¼Œä¸¦å†æ¬¡é™„ä¸Šæ”¯æ’ä½ è«–é»çš„ {current_year} å¹´æœ€æ–°è³‡æ–™å‡ºè™•ç¶²å€ã€‚
    """
            return prompt

    def run(self):
        print(f"=== æˆ°æƒ…å®¤é›™æ¦œå–®åˆ†æç³»çµ±å•Ÿå‹•: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===")

        self.load_all_clean_data()
        result_df = self.analyze_dual_leaderboards()

        if not result_df.empty:
            prompt = self.generate_ai_prompt(result_df)

            output_path = project_root / "data" / "daily_ai_prompt.txt"
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, "w", encoding="utf-8") as f:
                f.write(prompt)

            print(f"\nâœ… é›™æ¦œå–®æ·±åº¦åˆ†æå ±è¡¨ç”¢å‡ºæˆåŠŸï¼")
            print(f"ğŸ“ æª”æ¡ˆä½ç½®: {output_path}")
            print("-" * 50)
            print("ğŸ’¡ æç¤ºï¼šç¾åœ¨ AI èƒ½å¤ æ˜ç¢ºå€åˆ†ã€Œé‡é‡‘å‹•èƒ½è‚¡ã€èˆ‡ã€Œç„¡è²æ½›ä¼è‚¡ã€äº†ï¼Œå¿«è²¼çµ¦ Gemini æ¸¬è©¦çœ‹çœ‹ï¼")
            print("-" * 50)
        else:
            print("âš ï¸ è­¦å‘Šï¼šç„¡æ³•è¨ˆç®—å‡ºæ³¢æ®µæ•¸æ“šã€‚")


if __name__ == "__main__":
    analyzer = StrategyAnalyzer()
    analyzer.run()