# utils/etf/modules/parsers/capitalfund_parser.py
import pandas as pd
import json
from pathlib import Path


class CapitalFundParser:
    def __init__(self, raw_dir, clean_dir, etf_code="00982A"):
        self.raw_dir = Path(raw_dir)
        self.clean_dir = Path(clean_dir)
        self.etf_code = etf_code
        self.out_file = self.clean_dir / f"{etf_code}.csv"

    def parse_json(self, file_path: Path) -> pd.DataFrame:
        """è§£æå–®å€‹ JSONï¼Œå¼·åˆ¶å°‡è³‡æ–™æ—¥æœŸæ ¡æ­£å›æª”åæ—¥æœŸ"""
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        stocks = data.get("data", {}).get("stocks", [])
        if not stocks:
            return pd.DataFrame()

        df = pd.DataFrame(stocks)

        # 1. ç¯©é¸èˆ‡é‡æ–°å‘½åæ¬„ä½ (ä¸å†æå– date1)
        col_map = {
            "stocNo": "stock_code",
            "stocName": "stock_name",
            "share": "shares",
            "weight": "weight"
        }
        df = df[list(col_map.keys())].rename(columns=col_map)

        # 2. âœ¨ æ ¸å¿ƒä¿®æ­£ï¼šå¼·åˆ¶æ ¡æ­£å›æ­¸ T æ—¥
        # å¿½ç•¥æŠ•ä¿¡æ¨™è¨˜çš„ T+1ï¼Œç›´æ¥ç”¨æª”å (Tæ—¥) ä½œç‚ºçœŸå¯¦äº¤æ˜“æ—¥
        file_date_str = file_path.stem  # e.g., "20260223"
        trade_date = f"{file_date_str[:4]}-{file_date_str[4:6]}-{file_date_str[6:]}"
        df["date"] = trade_date

        # 3. ç¢ºä¿å‹åˆ¥æ­£ç¢º
        df["shares"] = df["shares"].astype(float).astype(int)
        df["weight"] = df["weight"].astype(float)

        return df

    def parse_all_files(self):
        """è§£æç›®éŒ„ä¸‹æ‰€æœ‰ JSON ä¸¦åˆä½µè¼¸å‡º CSV"""
        if not self.raw_dir.exists():
            print(f"âš ï¸ RAW_DIR ä¸å­˜åœ¨ï¼š{self.raw_dir}")
            return

        files = sorted(self.raw_dir.rglob("*.json"))
        if not files:
            print(f"âš ï¸ æ‰¾ä¸åˆ° JSON æª”æ¡ˆï¼š{self.raw_dir}")
            return

        print(f"ğŸ“‚ æ‰¾åˆ° {len(files)} å€‹ JSONï¼Œé–‹å§‹è§£æ {self.etf_code} ...")

        all_rows = []
        for f in files:
            try:
                df = self.parse_json(f)
                if not df.empty:
                    all_rows.append(df)
            except Exception as e:
                print(f"âš ï¸ è§£æå¤±æ•—ï¼š{f.name} ({e})")

        if not all_rows:
            print("âŒ æ²’æœ‰è§£æå‡ºä»»ä½•æœ‰æ•ˆè³‡æ–™")
            return

        # åˆä½µè³‡æ–™
        result = pd.concat(all_rows, ignore_index=True)

        # âœ¨ æ–°å¢ï¼šå…¨åŸŸå»é‡é˜²å‘†
        result = result.drop_duplicates(subset=['stock_code', 'date'], keep='last')

        # æ’åºèˆ‡è¼¸å‡º
        result = result.sort_values(by=["date", "weight"], ascending=[True, False])

        self.out_file.parent.mkdir(parents=True, exist_ok=True)
        result.to_csv(self.out_file, index=False, encoding="utf-8-sig")
        print(f"âœ… è§£æå®Œæˆï¼Œè¼¸å‡ºåˆ°ï¼š{self.out_file}")