"""
Goodinfo æœˆç‡Ÿæ”¶æ­·å¹´å‰å¹¾é«˜çˆ¬èŸ² (åˆä½µç‰ˆ)
æŠ“å–å–®æœˆç‡Ÿæ”¶æ­·æœˆæœ€é«˜æ’å 1-3 çš„è‚¡ç¥¨ï¼Œä¸¦åˆä½µå…©å€‹ URL çš„æ¬„ä½

ä½¿ç”¨æ–¹å¼:
1. å‘½ä»¤åˆ—:
   python crawler_goodinfo_revenue_high.py --mode fetch         # ç«‹å³æŠ“å– (æœ‰å¿«å–å°±è·³é)
   python crawler_goodinfo_revenue_high.py --mode fetch --force # å¼·åˆ¶é‡æ–°æŠ“å–
   python crawler_goodinfo_revenue_high.py --mode schedule --time 09:10  # æ’ç¨‹åŸ·è¡Œ

2. åœ¨ç¨‹å¼ä¸­ä½¿ç”¨:
   from utils.crawler_goodinfo_revenue_high import GoodinfoRevenueHighCrawler
   crawler = GoodinfoRevenueHighCrawler()
   df = crawler.fetch_data()  # è‡ªå‹•æª¢æŸ¥å¿«å–
"""

import sys
from pathlib import Path

# ç¢ºä¿å¯ä»¥ import utils æ¨¡çµ„
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import pandas as pd
import schedule
import time
import re
from utils.crawler_goodinfo_base import GoodinfoBaseCrawler
import os
print("=" * 60, flush=True)
print("ğŸ” è¨ºæ–·è³‡è¨Š:", flush=True)
print(f"ç•¶å‰å·¥ä½œç›®éŒ„: {os.getcwd()}", flush=True)
print(f"__file__: {__file__}", flush=True)
print(f"__file__.parent: {Path(__file__).parent}", flush=True)
print(f"__file__.parent.parent: {Path(__file__).parent.parent}", flush=True)

CHROMEDRIVER_PATH = Path(__file__).parent.parent / "chromedriver-win64" / "chromedriver.exe"
print(f"ChromeDriver è·¯å¾‘: {CHROMEDRIVER_PATH}", flush=True)
print(f"ChromeDriver å­˜åœ¨: {CHROMEDRIVER_PATH.exists()}", flush=True)

if not CHROMEDRIVER_PATH.exists():
    print(f"âŒ ChromeDriver ä¸å­˜åœ¨!", flush=True)
    print(f"ç•¶å‰ç›®éŒ„å…§å®¹: {list(Path(os.getcwd()).iterdir())[:10]}", flush=True)
print("=" * 60, flush=True)
sys.stdout.flush()
class GoodinfoRevenueHighCrawler(GoodinfoBaseCrawler):
    """æœˆç‡Ÿæ”¶æ­·å¹´å‰å¹¾é«˜çˆ¬èŸ² (åˆä½µç‰ˆ)"""

    # URL 1: æœˆç‡Ÿæ”¶å‰µç´€éŒ„çµ±è¨ˆ (åŒ…å«æ’åã€å‰µç´€éŒ„æœˆæ•¸ç­‰æ¬„ä½)
    URL = ('https://goodinfo.tw/tw/StockList.asp?MARKET_CAT=%E8%87%AA%E8%A8%82%E7%AF%A9%E9%81%B8'
           '&INDUSTRY_CAT=%E6%88%91%E7%9A%84%E6%A2%9D%E4%BB%B6&FL_ITEM0=%E5%96%AE%E6%9C%88%E7%87%9F'
           '%E6%94%B6%E6%AD%B7%E6%9C%88%E6%9C%80%E9%AB%98%E6%8E%92%E5%90%8D&FL_VAL_S0=1&FL_VAL_E0=3'
           '&FL_ITEM1=&FL_VAL_S1=&FL_VAL_E1=&FL_ITEM2=&FL_VAL_S2=&FL_VAL_E2=&FL_ITEM3=&FL_VAL_S3='
           '&FL_VAL_E3=&FL_ITEM4=&FL_VAL_S4=&FL_VAL_E4=&FL_ITEM5=&FL_VAL_S5=&FL_VAL_E5=&FL_ITEM6='
           '&FL_VAL_S6=&FL_VAL_E6=&FL_ITEM7=&FL_VAL_S7=&FL_VAL_E7=&FL_ITEM8=&FL_VAL_S8=&FL_VAL_E8='
           '&FL_ITEM9=&FL_VAL_S9=&FL_VAL_E9=&FL_ITEM10=&FL_VAL_S10=&FL_VAL_E10=&FL_ITEM11='
           '&FL_VAL_S11=&FL_VAL_E11=&FL_RULE0=&FL_RULE1=&FL_RULE2=&FL_RULE3=&FL_RULE4=&FL_RULE5='
           '&FL_RANK0=&FL_RANK1=&FL_RANK2=&FL_RANK3=&FL_RANK4=&FL_RANK5=&FL_FD0=&FL_FD1=&FL_FD2='
           '&FL_FD3=&FL_FD4=&FL_FD5=&FL_SHEET=%E7%87%9F%E6%94%B6%E7%8B%80%E6%B3%81&FL_SHEET2='
           '%E6%9C%88%E7%87%9F%E6%94%B6%E5%89%B5%E7%B4%80%E9%8C%84%E7%B5%B1%E8%A8%88&FL_MARKET='
           '%E4%B8%8A%E5%B8%82%2F%E4%B8%8A%E6%AB%83&FL_QRY=%E6%9F%A5++%E8%A9%A2')

    # URL 2: æœˆç‡Ÿæ”¶ç‹€æ³ (åŒ…å«æœˆå¢ã€å¹´å¢ç­‰è©³ç´°æ¬„ä½)
    URL2 = ('https://goodinfo.tw/tw/StockList.asp?MARKET_CAT=%E8%87%AA%E8%A8%82%E7%AF%A9%E9%81%B8'
            '&INDUSTRY_CAT=%E6%88%91%E7%9A%84%E6%A2%9D%E4%BB%B6&FL_ITEM0=%E5%96%AE%E6%9C%88%E7%87%9F'
            '%E6%94%B6%E6%AD%B7%E6%9C%88%E6%9C%80%E9%AB%98%E6%8E%92%E5%90%8D&FL_VAL_S0=1&FL_VAL_E0=3'
            '&FL_ITEM1=&FL_VAL_S1=&FL_VAL_E1=&FL_ITEM2=&FL_VAL_S2=&FL_VAL_E2=&FL_ITEM3=&FL_VAL_S3='
            '&FL_VAL_E3=&FL_ITEM4=&FL_VAL_S4=&FL_VAL_E4=&FL_ITEM5=&FL_VAL_S5=&FL_VAL_E5=&FL_ITEM6='
            '&FL_VAL_S6=&FL_VAL_E6=&FL_ITEM7=&FL_VAL_S7=&FL_VAL_E7=&FL_ITEM8=&FL_VAL_S8=&FL_VAL_E8='
            '&FL_ITEM9=&FL_VAL_S9=&FL_VAL_E9=&FL_ITEM10=&FL_VAL_S10=&FL_VAL_E10=&FL_ITEM11='
            '&FL_VAL_S11=&FL_VAL_E11=&FL_RULE0=&FL_RULE1=&FL_RULE2=&FL_RULE3=&FL_RULE4=&FL_RULE5='
            '&FL_RANK0=&FL_RANK1=&FL_RANK2=&FL_RANK3=&FL_RANK4=&FL_RANK5=&FL_FD0=&FL_FD1=&FL_FD2='
            '&FL_FD3=&FL_FD4=&FL_FD5=&FL_SHEET=%E7%87%9F%E6%94%B6%E7%8B%80%E6%B3%81&FL_SHEET2='
            '%E6%9C%88%E7%87%9F%E6%94%B6%E7%8B%80%E6%B3%81&FL_MARKET='
            '%E4%B8%8A%E5%B8%82%2F%E4%B8%8A%E6%AB%83&FL_QRY=%E6%9F%A5++%E8%A9%A2')

    FILENAME_SUFFIX = "æœˆç‡Ÿæ”¶å‰µæ–°é«˜"

    # åŸºæœ¬æ•¸å€¼æ¬„ä½ (åŒ…å«å…©å€‹ URL çš„æ•¸å€¼æ¬„ä½)
    BASIC_NUMERIC_COLUMNS = [
        'æˆäº¤', 'æ¼²è·Œ åƒ¹', 'æ¼²è·Œ å¹…', 'æˆäº¤ å¼µæ•¸',
        'å–®æœˆ ç‡Ÿæ”¶ (å„„)', 'ç´¯æœˆ ç‡Ÿæ”¶ (å„„)',
        'å–®æœˆ ç‡Ÿæ”¶ æœˆå¢ (å„„)', 'å–®æœˆ ç‡Ÿæ”¶ æœˆå¢ (%)',
        'å–®æœˆ ç‡Ÿæ”¶ å¹´å¢ (å„„)', 'å–®æœˆ ç‡Ÿæ”¶ å¹´å¢ (%)',
        'ç´¯æœˆ ç‡Ÿæ”¶ å¹´å¢ (å„„)', 'ç´¯æœˆ ç‡Ÿæ”¶ å¹´å¢ (%)'
    ]

    # éœ€è¦è§£æç‚ºæ•¸å€¼çš„æ¬„ä½ï¼ˆæ’åï¼‰
    RANK_COLUMNS = [
        'å–®æœˆ ç‡Ÿæ”¶ æ­·æœˆ æ’å',
        'å–®æœˆ ç‡Ÿæ”¶ æ­·å¹´ æ’å',
        'ç´¯æœˆ ç‡Ÿæ”¶ æ­·å¹´ æ’å'
    ]

    # ä¿ç•™ç‚ºæ–‡å­—çš„æ¬„ä½ï¼ˆå«å¢æ¸›è³‡è¨Šï¼‰
    TEXT_COLUMNS = [
        'å–®æœˆ ç‡Ÿæ”¶ å‰µç´€éŒ„ æœˆæ•¸',
        'å–®æœˆ ç‡Ÿæ”¶ é€£å¢æ¸› æœˆæ•¸',
        'å–®æœˆ ç‡Ÿæ”¶ å‰µç´€éŒ„ å¹´æ•¸',
        'ç´¯æœˆ ç‡Ÿæ”¶ å‰µç´€éŒ„ å¹´æ•¸',
        'ç´¯æœˆ ç‡Ÿæ”¶ é€£å¢æ¸› å¹´æ•¸',
        'æœˆç‡Ÿæ”¶ å¢æ¸› è¨»è¨˜'  # æ–°å¢: åŒ…å« âŠ• âŠ™ ç­‰ç¬¦è™Ÿ
    ]

    def __init__(self):
        super().__init__(data_subdir="revenue_high")

    def _parse_goodinfo_rank_column(self, series: pd.Series) -> pd.Series:
        """
        è§£æ Goodinfo çš„æ’åæ¬„ä½
        ä¾‹å¦‚: "1é«˜" -> 1, "2é«˜" -> 2, "å¢â†’æ¸›" -> 0, "3é«˜" -> 3

        Args:
            series: åŸå§‹æ¬„ä½

        Returns:
            è§£æå¾Œçš„æ•¸å€¼æ¬„ä½
        """
        def extract_rank(value):
            if pd.isna(value):
                return None

            value_str = str(value).strip()

            # å¦‚æœåŒ…å«"å¢"æˆ–"æ¸›"ä½†æ²’æœ‰æ•¸å­—ï¼Œè¿”å› 0
            if ('å¢' in value_str or 'æ¸›' in value_str) and not any(c.isdigit() for c in value_str):
                return 0

            # æå–æ•¸å­—
            match = re.search(r'(\d+)', value_str)
            if match:
                return int(match.group(1))

            return None

        return series.apply(extract_rank)

    def _parse_goodinfo_month_year_column(self, series: pd.Series) -> pd.Series:
        """
        è§£æåŒ…å«æœˆæ•¸/å¹´æ•¸çš„æ¬„ä½
        ä¾‹å¦‚: "95å€‹æœˆé«˜" -> 95, "29å¹´é«˜" -> 29, "é€£2å¢" -> 2, "3å¢â†’æ¸›" -> 0, "4æ¸›â†’å¢" -> 0

        Args:
            series: åŸå§‹æ¬„ä½

        Returns:
            è§£æå¾Œçš„æ•¸å€¼æ¬„ä½
        """
        def extract_number(value):
            if pd.isna(value):
                return None

            value_str = str(value).strip()

            # è™•ç† "Xå¢â†’æ¸›" æˆ– "Xæ¸›â†’å¢" (è¡¨ç¤ºè½‰æŠ˜ï¼Œè¿”å› 0)
            if 'â†’' in value_str:
                return 0

            # è™•ç† "é€£Xå¢" æˆ– "é€£Xæ¸›" çš„æƒ…æ³
            if 'é€£' in value_str:
                match = re.search(r'é€£(\d+)', value_str)
                if match:
                    num = int(match.group(1))
                    # å¦‚æœæ˜¯"é€£Xæ¸›"ï¼Œè¿”å›è² æ•¸
                    if 'æ¸›' in value_str:
                        return -num
                    return num

            # ä¸€èˆ¬æƒ…æ³ï¼Œæå–æ•¸å­—
            match = re.search(r'(\d+)', value_str)
            if match:
                return int(match.group(1))

            return None

        return series.apply(extract_number)

    def fetch_data(self, force: bool = False) -> pd.DataFrame:
        """
        æŠ“å–è³‡æ–™ä¸¦åˆä½µå…©å€‹ URL çš„æ¬„ä½

        Args:
            force: æ˜¯å¦å¼·åˆ¶æŠ“å–ï¼ˆå¿½ç•¥æœ¬æ©Ÿå¿«å–ï¼‰

        Returns:
            DataFrame (åˆä½µå¾Œçš„å®Œæ•´è³‡æ–™)
        """
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰ä»Šæ—¥è³‡æ–™
        if not force and self._file_exists_for_today(self.FILENAME_SUFFIX):
            self.logger.info(f"æœ¬æ©Ÿå·²æœ‰ä»Šæ—¥è³‡æ–™ï¼Œè·³éæŠ“å–")
            return self._load_today_data(self.FILENAME_SUFFIX)

        self.logger.info(f"é–‹å§‹æŠ“å–: {self.FILENAME_SUFFIX}")

        # æœ€å¤šé‡è©¦ 3 æ¬¡æ•´å€‹æŠ“å–æµç¨‹
        max_attempts = 3
        for attempt in range(1, max_attempts + 1):
            try:
                # === æ­¥é©Ÿ 1: æŠ“å– URL1 (æœˆç‡Ÿæ”¶å‰µç´€éŒ„çµ±è¨ˆ) ===
                self.logger.info(f"[å˜—è©¦ {attempt}/{max_attempts}] æŠ“å– URL1: æœˆç‡Ÿæ”¶å‰µç´€éŒ„çµ±è¨ˆæ¬„ä½")
                df1 = self._fetch_with_retry(self.URL)
                self.logger.info(f"âœ“ URL1 æŠ“å–æˆåŠŸï¼Œ{len(df1)} ç­†è³‡æ–™ï¼Œ{len(df1.columns)} å€‹æ¬„ä½")

                # === æ­¥é©Ÿ 2: ç­‰å¾…ä¸€æ®µæ™‚é–“ï¼Œé¿å…è¢«ç¶²ç«™é™åˆ¶ ===
                wait_time = 3 + (attempt - 1) * 2  # ç¬¬1æ¬¡ç­‰3ç§’ï¼Œç¬¬2æ¬¡ç­‰5ç§’ï¼Œç¬¬3æ¬¡ç­‰7ç§’
                self.logger.info(f"ç­‰å¾… {wait_time} ç§’å¾ŒæŠ“å–ç¬¬äºŒå€‹ URL...")
                time.sleep(wait_time)

                # === æ­¥é©Ÿ 3: æŠ“å– URL2 (æœˆç‡Ÿæ”¶ç‹€æ³) ===
                self.logger.info(f"[å˜—è©¦ {attempt}/{max_attempts}] æŠ“å– URL2: æœˆç‡Ÿæ”¶ç‹€æ³æ¬„ä½")
                df2 = self._fetch_with_retry(self.URL2)
                self.logger.info(f"âœ“ URL2 æŠ“å–æˆåŠŸï¼Œ{len(df2)} ç­†è³‡æ–™ï¼Œ{len(df2.columns)} å€‹æ¬„ä½")

                # å¦‚æœæˆåŠŸæŠ“å–å…©å€‹ URLï¼Œè·³å‡ºé‡è©¦è¿´åœˆ
                break

            except Exception as e:
                self.logger.error(f"âœ— ç¬¬ {attempt} æ¬¡å˜—è©¦å¤±æ•—: {str(e)}")
                if attempt < max_attempts:
                    wait_time = 10 * attempt  # å¤±æ•—å¾Œç­‰æ›´ä¹…ï¼š10ç§’ã€20ç§’ã€30ç§’
                    self.logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                else:
                    self.logger.error(f"âœ— å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼ŒæŠ“å–å¤±æ•—")
                    raise

        # === æ­¥é©Ÿ 4: åˆä½µå…©å€‹ DataFrame ===
        self.logger.info("é–‹å§‹åˆä½µå…©å€‹è³‡æ–™è¡¨...")

        # æ‰¾å‡º df2 ä¸­ç¨æœ‰çš„æ¬„ä½ï¼ˆæ’é™¤ df1 å·²æœ‰çš„ï¼‰
        df1_cols = set(df1.columns)
        df2_unique_cols = [col for col in df2.columns if col not in df1_cols]

        self.logger.info(f"df2 ç¨æœ‰æ¬„ä½: {df2_unique_cols}")

        # df2 ä¿ç•™ï¼šä»£è™Ÿ(ç”¨æ–¼åˆä½µ) + ç¨æœ‰æ¬„ä½
        cols_to_keep = ['ä»£è™Ÿ'] + df2_unique_cols
        df2_filtered = df2[cols_to_keep].copy()

        self.logger.info(f"æº–å‚™åˆä½µï¼Œdf2_filtered æ¬„ä½: {list(df2_filtered.columns)}")

        # ä½¿ç”¨å·¦é€£æ¥åˆä½µï¼ˆä»¥ df1 ç‚ºä¸»ï¼‰
        df = pd.merge(df1, df2_filtered, on='ä»£è™Ÿ', how='left', suffixes=('', '_dup'))

        # ç§»é™¤å¯èƒ½çš„é‡è¤‡æ¬„ä½
        df = df.loc[:, ~df.columns.str.endswith('_dup')]

        self.logger.info(f"âœ“ åˆä½µå®Œæˆï¼Œå…± {len(df)} ç­†è³‡æ–™ï¼Œ{len(df.columns)} å€‹æ¬„ä½")

        # === æ­¥é©Ÿ 5: æ¸…ç†æ¬„ä½åç¨±ï¼ˆç§»é™¤ç©ºç™½ï¼‰ ===
        original_cols = df.columns.tolist()
        df.columns = df.columns.str.replace(' ', '', regex=False)
        self.logger.info(f"âœ“ æ¬„ä½åç¨±å·²æ¸…ç†ï¼ˆç§»é™¤ç©ºç™½ï¼‰")

        # åŒæ™‚æ›´æ–°æ¬„ä½å®šç¾©åˆ—è¡¨ï¼ˆç”¨æ–¼å¾ŒçºŒè™•ç†ï¼‰
        basic_numeric_cols = [col.replace(' ', '') for col in self.BASIC_NUMERIC_COLUMNS]
        rank_cols = [col.replace(' ', '') for col in self.RANK_COLUMNS]
        text_cols = [col.replace(' ', '') for col in self.TEXT_COLUMNS]

        # === æ­¥é©Ÿ 6: è½‰æ›æ•¸å€¼æ¬„ä½ ===
        df = self._convert_numeric_columns(df, basic_numeric_cols)

        # === æ­¥é©Ÿ 7: è§£ææ’åæ¬„ä½ ===
        for col in rank_cols:
            if col in df.columns:
                self.logger.info(f"è§£ææ’åæ¬„ä½: {col}")
                df[col] = self._parse_goodinfo_rank_column(df[col])

        # === æ­¥é©Ÿ 8: ä¿ç•™æ–‡å­—æ¬„ä½ ===
        for col in text_cols:
            if col in df.columns:
                self.logger.info(f"ä¿ç•™æ–‡å­—æ¬„ä½: {col}")
                df[col] = df[col].astype(str).str.strip()
                # æ¸…ç† 'nan' å­—ä¸²
                df[col] = df[col].replace('nan', '')

        self.logger.info(f"âœ“ è³‡æ–™è™•ç†å®Œæˆ")

        # === æ­¥é©Ÿ 7: å„²å­˜æª”æ¡ˆ ===
        filepath = self._generate_filename(df, self.FILENAME_SUFFIX)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        self.logger.info(f"âœ“ è³‡æ–™å·²å„²å­˜è‡³: {filepath}")

        return df

    def schedule_daily_fetch(self, time_str: str = "09:10"):
        """
        æ’ç¨‹æ¯æ—¥æŠ“å–

        Args:
            time_str: åŸ·è¡Œæ™‚é–“ï¼Œæ ¼å¼ "HH:MM"ï¼Œé è¨­ 09:10 (ç‡Ÿæ”¶å…¬å‘Šå¾Œ)
        """
        self.logger.info(f"è¨­å®šæ’ç¨‹: æ¯æ—¥ {time_str} åŸ·è¡Œ")

        def job():
            self.logger.info(f"æ’ç¨‹ä»»å‹™åŸ·è¡Œä¸­...")
            try:
                self.fetch_data(force=False)
            except Exception as e:
                self.logger.error(f"æ’ç¨‹ä»»å‹™åŸ·è¡Œå¤±æ•—: {str(e)}")

        schedule.every().day.at(time_str).do(job)

        self.logger.info("æ’ç¨‹å·²å•Ÿå‹•ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)
        except KeyboardInterrupt:
            self.logger.info("æ’ç¨‹å·²åœæ­¢")

    def get_filtered_stocks(self,
                           max_monthly_rank: int = None,
                           max_yearly_rank: int = None,
                           min_revenue: float = None,
                           min_mom_growth: float = None,
                           min_yoy_growth: float = None,
                           growth_pattern: str = None,
                           has_positive_note: bool = None) -> pd.DataFrame:
        """
        å–å¾—ç¬¦åˆæ¢ä»¶çš„æœˆç‡Ÿæ”¶å‰µæ–°é«˜è‚¡ç¥¨ (é€²éšç‰ˆ)

        Args:
            max_monthly_rank: å–®æœˆç‡Ÿæ”¶æ­·æœˆæ’åæœ€å¤§å€¼ (ä¾‹å¦‚: 3 ä»£è¡¨åªè¦å‰3å)
            max_yearly_rank: å–®æœˆç‡Ÿæ”¶æ­·å¹´æ’åæœ€å¤§å€¼
            min_revenue: å–®æœˆç‡Ÿæ”¶æœ€å°å€¼ (å„„)
            min_mom_growth: å–®æœˆç‡Ÿæ”¶æœˆå¢ç‡æœ€å°å€¼ (%)
            min_yoy_growth: å–®æœˆç‡Ÿæ”¶å¹´å¢ç‡æœ€å°å€¼ (%)
            growth_pattern: æˆé•·æ¨¡å¼ç¯©é¸ï¼Œä¾‹å¦‚: "é€£" (åŒ…å«é€£çºŒæˆé•·), "å¢" (åŒ…å«å¢), "æ¸›" (åŒ…å«æ¸›)
            has_positive_note: æ˜¯å¦æœ‰æ­£å‘è¨»è¨˜ (âŠ•)

        Returns:
            ç¯©é¸å¾Œçš„ DataFrame
        """
        df = self.fetch_data()

        # åŸæœ‰çš„æ’åå’Œç‡Ÿæ”¶ç¯©é¸ï¼ˆæ¬„ä½åç¨±å·²ç„¡ç©ºç™½ï¼‰
        if max_monthly_rank is not None and 'å–®æœˆç‡Ÿæ”¶æ­·æœˆæ’å' in df.columns:
            df = df[df['å–®æœˆç‡Ÿæ”¶æ­·æœˆæ’å'] <= max_monthly_rank]

        if max_yearly_rank is not None and 'å–®æœˆç‡Ÿæ”¶æ­·å¹´æ’å' in df.columns:
            df = df[df['å–®æœˆç‡Ÿæ”¶æ­·å¹´æ’å'] <= max_yearly_rank]

        if min_revenue is not None and 'å–®æœˆç‡Ÿæ”¶(å„„)' in df.columns:
            df = df[df['å–®æœˆç‡Ÿæ”¶(å„„)'] >= min_revenue]

        # æ–°å¢: æœˆå¢ç‡ç¯©é¸
        if min_mom_growth is not None and 'å–®æœˆç‡Ÿæ”¶æœˆå¢(%)' in df.columns:
            df = df[df['å–®æœˆç‡Ÿæ”¶æœˆå¢(%)'] >= min_mom_growth]

        # æ–°å¢: å¹´å¢ç‡ç¯©é¸
        if min_yoy_growth is not None and 'å–®æœˆç‡Ÿæ”¶å¹´å¢(%)' in df.columns:
            df = df[df['å–®æœˆç‡Ÿæ”¶å¹´å¢(%)'] >= min_yoy_growth]

        # æˆé•·æ¨¡å¼ç¯©é¸
        if growth_pattern is not None and 'å–®æœˆç‡Ÿæ”¶é€£å¢æ¸›æœˆæ•¸' in df.columns:
            df = df[df['å–®æœˆç‡Ÿæ”¶é€£å¢æ¸›æœˆæ•¸'].str.contains(growth_pattern, na=False)]

        # æ–°å¢: æ­£å‘è¨»è¨˜ç¯©é¸
        if has_positive_note is not None and 'æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜' in df.columns:
            if has_positive_note:
                df = df[df['æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜'].str.contains('âŠ•', na=False)]
            else:
                df = df[~df['æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜'].str.contains('âŠ•', na=False)]

        return df


def main():
    """å‘½ä»¤åˆ—å…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='Goodinfo æœˆç‡Ÿæ”¶å‰µæ–°é«˜çˆ¬èŸ² (åˆä½µç‰ˆ)')
    parser.add_argument('--mode', choices=['fetch', 'schedule', 'filter', 'test'], default='fetch',
                       help='åŸ·è¡Œæ¨¡å¼: fetch(ç«‹å³æŠ“å–), schedule(æ’ç¨‹åŸ·è¡Œ), filter(æ¢ä»¶ç¯©é¸), test(æ¸¬è©¦æ¨¡å¼)')
    parser.add_argument('--force', action='store_true',
                       help='å¼·åˆ¶æŠ“å–ï¼Œå¿½ç•¥æœ¬æ©Ÿå¿«å– (é è¨­: æœ‰å¿«å–å°±ç”¨å¿«å–)')
    parser.add_argument('--time', default='09:10',
                       help='æ’ç¨‹æ™‚é–“ (æ ¼å¼: HH:MM)ï¼Œé è¨­ 09:10')
    parser.add_argument('--monthly-rank', type=int,
                       help='å–®æœˆç‡Ÿæ”¶æ­·æœˆæ’åæœ€å¤§å€¼ï¼Œä¾‹å¦‚: --monthly-rank 3 (åªè¦å‰3å)')
    parser.add_argument('--yearly-rank', type=int,
                       help='å–®æœˆç‡Ÿæ”¶æ­·å¹´æ’åæœ€å¤§å€¼')
    parser.add_argument('--min-revenue', type=float,
                       help='å–®æœˆç‡Ÿæ”¶æœ€å°å€¼(å„„)ï¼Œä¾‹å¦‚: --min-revenue 10')
    parser.add_argument('--min-mom-growth', type=float,
                       help='å–®æœˆç‡Ÿæ”¶æœˆå¢ç‡æœ€å°å€¼(%)ï¼Œä¾‹å¦‚: --min-mom-growth 10')
    parser.add_argument('--min-yoy-growth', type=float,
                       help='å–®æœˆç‡Ÿæ”¶å¹´å¢ç‡æœ€å°å€¼(%)ï¼Œä¾‹å¦‚: --min-yoy-growth 20')
    parser.add_argument('--growth-pattern', type=str,
                       help='æˆé•·æ¨¡å¼ï¼Œä¾‹å¦‚: --growth-pattern "é€£3å¢" æˆ– "å¢" æˆ– "â†’"')
    parser.add_argument('--positive-note', action='store_true',
                       help='åªé¡¯ç¤ºæœ‰æ­£å‘è¨»è¨˜(âŠ•)çš„è‚¡ç¥¨')

    args = parser.parse_args()

    crawler = GoodinfoRevenueHighCrawler()

    if args.mode == 'test':
        # ============================================================
        # æ¸¬è©¦å€å¡Š - ç”¨æ–¼é–‹ç™¼æ¸¬è©¦ï¼Œæ­£å¼ä½¿ç”¨å¾Œå¯ç§»é™¤
        # ============================================================
        print("\n" + "="*100)
        print("æ¸¬è©¦æ¨¡å¼: é©—è­‰åˆä½µåŠŸèƒ½")
        print("="*100 + "\n")

        try:
            df = crawler.fetch_data(force=True)

            print(f"âœ“ è³‡æ–™æŠ“å–æˆåŠŸ")
            print(f"  ç¸½ç­†æ•¸: {len(df)}")
            print(f"  ç¸½æ¬„ä½æ•¸: {len(df.columns)}")
            print(f"\næ‰€æœ‰æ¬„ä½:")
            for i, col in enumerate(df.columns, 1):
                print(f"  {i:2d}. {col}")

            # æª¢æŸ¥é—œéµæ¬„ä½
            print(f"\né—œéµæ¬„ä½æª¢æŸ¥:")
            key_cols = ['ä»£è™Ÿ', 'åç¨±', 'å–®æœˆç‡Ÿæ”¶(å„„)', 'å–®æœˆç‡Ÿæ”¶æœˆå¢(%)',
                       'å–®æœˆç‡Ÿæ”¶å¹´å¢(%)', 'æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜']
            for col in key_cols:
                exists = "âœ“" if col in df.columns else "âœ—"
                print(f"  {exists} {col}")

            # é¡¯ç¤ºå‰5ç­†å®Œæ•´è³‡æ–™
            print(f"\nå‰5ç­†è³‡æ–™é è¦½:")
            display_cols = ['ä»£è™Ÿ', 'åç¨±', 'æˆäº¤', 'ç‡Ÿæ”¶æœˆä»½', 'å–®æœˆç‡Ÿæ”¶(å„„)',
                           'å–®æœˆç‡Ÿæ”¶æœˆå¢(%)', 'å–®æœˆç‡Ÿæ”¶å¹´å¢(%)',
                           'å–®æœˆç‡Ÿæ”¶æ­·æœˆæ’å', 'æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜']
            available_cols = [col for col in display_cols if col in df.columns]
            pd.set_option('display.max_columns', None)
            pd.set_option('display.width', None)
            print(df[available_cols].head(5).to_string(index=False))

            # æ¸¬è©¦é€²éšç¯©é¸
            print(f"\næ¸¬è©¦é€²éšç¯©é¸: æœˆå¢ç‡ > 10% ä¸” å¹´å¢ç‡ > 20%")
            filtered = crawler.get_filtered_stocks(
                min_mom_growth=10,
                min_yoy_growth=20
            )
            print(f"  ç¬¦åˆæ¢ä»¶: {len(filtered)} æª”")
            if len(filtered) > 0:
                print(filtered[available_cols].head(3).to_string(index=False))

            print(f"\nâœ“ æ¸¬è©¦å®Œæˆï¼ŒåŠŸèƒ½æ­£å¸¸")

        except Exception as e:
            print(f"\nâœ— æ¸¬è©¦å¤±æ•—: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        # ============================================================
        # æ¸¬è©¦å€å¡ŠçµæŸ
        # ============================================================

    elif args.mode == 'fetch':
        try:
            df = crawler.fetch_data(force=args.force)
            if df is not None:
                print(f"\n{'='*100}")
                print(f"âœ“ æˆåŠŸæŠ“å– {len(df)} ç­†æœˆç‡Ÿæ”¶å‰µæ–°é«˜è‚¡ç¥¨ (å®Œæ•´ç‰ˆ)")
                print(f"{'='*100}\n")

                # é¡¯ç¤ºå‰ 15 ç­†
                display_cols = ['ä»£è™Ÿ', 'åç¨±', 'æˆäº¤', 'æ¼²è·Œå¹…', 'ç‡Ÿæ”¶æœˆä»½',
                               'å–®æœˆç‡Ÿæ”¶(å„„)', 'å–®æœˆç‡Ÿæ”¶æœˆå¢(%)', 'å–®æœˆç‡Ÿæ”¶å¹´å¢(%)',
                               'å–®æœˆç‡Ÿæ”¶æ­·æœˆæ’å', 'æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜']
                available_cols = [col for col in display_cols if col in df.columns]

                # æ ¼å¼åŒ–é¡¯ç¤º
                pd.set_option('display.max_columns', None)
                pd.set_option('display.width', None)
                pd.set_option('display.float_format', lambda x: f'{x:.2f}' if pd.notna(x) else 'N/A')

                print(df[available_cols].head(15).to_string(index=False))
                print(f"\n... (å…± {len(df)} ç­†)")

                # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
                print(f"\nçµ±è¨ˆè³‡è¨Š:")
                print(f"  æ­·æœˆç¬¬1å: {len(df[df['å–®æœˆç‡Ÿæ”¶æ­·æœˆæ’å'] == 1])} æª”")
                print(f"  æ­·å¹´ç¬¬1å: {len(df[df['å–®æœˆç‡Ÿæ”¶æ­·å¹´æ’å'] == 1])} æª”")

                if 'å–®æœˆç‡Ÿæ”¶æœˆå¢(%)' in df.columns:
                    mom_positive = df[df['å–®æœˆç‡Ÿæ”¶æœˆå¢(%)'] > 0]
                    print(f"  æœˆå¢ç‡ > 0%: {len(mom_positive)} æª”")

                if 'å–®æœˆç‡Ÿæ”¶å¹´å¢(%)' in df.columns:
                    yoy_positive = df[df['å–®æœˆç‡Ÿæ”¶å¹´å¢(%)'] > 0]
                    print(f"  å¹´å¢ç‡ > 0%: {len(yoy_positive)} æª”")

                if 'æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜' in df.columns:
                    positive_notes = df[df['æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜'].str.contains('âŠ•', na=False)]
                    print(f"  æœ‰æ­£å‘è¨»è¨˜(âŠ•): {len(positive_notes)} æª”")

        except Exception as e:
            print(f"\nâœ— æŠ“å–å¤±æ•—: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.exit(1)

    elif args.mode == 'schedule':
        crawler.schedule_daily_fetch(time_str=args.time)

    elif args.mode == 'filter':
        try:
            df = crawler.get_filtered_stocks(
                max_monthly_rank=args.monthly_rank,
                max_yearly_rank=args.yearly_rank,
                min_revenue=args.min_revenue,
                min_mom_growth=args.min_mom_growth,
                min_yoy_growth=args.min_yoy_growth,
                growth_pattern=args.growth_pattern,
                has_positive_note=args.positive_note if hasattr(args, 'positive_note') else None
            )

            conditions = []
            if args.monthly_rank:
                conditions.append(f"æ­·æœˆæ’å <= {args.monthly_rank}")
            if args.yearly_rank:
                conditions.append(f"æ­·å¹´æ’å <= {args.yearly_rank}")
            if args.min_revenue:
                conditions.append(f"å–®æœˆç‡Ÿæ”¶ >= {args.min_revenue} å„„")
            if args.min_mom_growth:
                conditions.append(f"æœˆå¢ç‡ >= {args.min_mom_growth}%")
            if args.min_yoy_growth:
                conditions.append(f"å¹´å¢ç‡ >= {args.min_yoy_growth}%")
            if args.growth_pattern:
                conditions.append(f"é€£å¢æ¸›æ¨¡å¼åŒ…å« '{args.growth_pattern}'")
            if args.positive_note:
                conditions.append("æœ‰æ­£å‘è¨»è¨˜(âŠ•)")

            print(f"\n{'='*100}")
            print(f"âœ“ æ‰¾åˆ° {len(df)} æª”ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
            if conditions:
                print(f"  æ¢ä»¶: {' & '.join(conditions)}")
            print(f"{'='*100}\n")

            display_cols = ['ä»£è™Ÿ', 'åç¨±', 'æˆäº¤', 'ç‡Ÿæ”¶æœˆä»½', 'å–®æœˆç‡Ÿæ”¶(å„„)',
                           'å–®æœˆç‡Ÿæ”¶æœˆå¢(%)', 'å–®æœˆç‡Ÿæ”¶å¹´å¢(%)',
                           'å–®æœˆç‡Ÿæ”¶æ­·æœˆæ’å', 'å–®æœˆç‡Ÿæ”¶æ­·å¹´æ’å',
                           'æœˆç‡Ÿæ”¶å¢æ¸›è¨»è¨˜']
            available_cols = [col for col in display_cols if col in df.columns]

            if len(df) > 0:
                pd.set_option('display.float_format', lambda x: f'{x:.2f}' if pd.notna(x) else 'N/A')
                print(df[available_cols].to_string(index=False))
            else:
                print("æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
        except Exception as e:
            print(f"\nâœ— ç¯©é¸å¤±æ•—: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.exit(1)


if __name__ == "__main__":
    print(f"DEBUG: ç¨‹å¼é–‹å§‹åŸ·è¡Œ")
    print(f"DEBUG: Python è·¯å¾‘: {sys.path}")
    print(f"DEBUG: ç•¶å‰ç›®éŒ„: {Path.cwd()}")
    print(f"DEBUG: å°ˆæ¡ˆæ ¹ç›®éŒ„: {project_root}")

    try:
        main()
    except Exception as e:
        print(f"\nç¨‹å¼åŸ·è¡Œå¤±æ•—:")
        print(f"éŒ¯èª¤é¡å‹: {type(e).__name__}")
        print(f"éŒ¯èª¤è¨Šæ¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)