"""
è³‡æ–™ä¸‹è¼‰å™¨æ¨¡çµ„
è² è²¬å¾ yfinance ä¸‹è¼‰è‚¡ç¥¨è³‡æ–™ä¸¦æ›´æ–°å¿«å–
(å·²ä¿®æ­£ï¼šå¼·åˆ¶ä¸å¾©æ¬Š + æ”¯æ´å¼·åˆ¶æ›´æ–°æŒ‡ä»¤å‚³é)
"""

import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
from typing import Optional, List, Dict
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import json
import os
import sys

# è™•ç†ç›¸å°å¼•ç”¨å•é¡Œ
try:
    from .manager import CacheManager
except ImportError:
    # ç›´æ¥åŸ·è¡Œæ™‚ï¼ŒåŠ å…¥çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent))
    from manager import CacheManager


class StockDownloader:
    """è‚¡ç¥¨è³‡æ–™ä¸‹è¼‰å™¨"""

    def __init__(self, cache_manager: Optional[CacheManager] = None,
                 proxy: Optional[str] = None):
        """
        åˆå§‹åŒ–ä¸‹è¼‰å™¨
        """
        self.cache = cache_manager or CacheManager()
        self.logger = self.cache.logger

        # è¨­å®š proxy
        self.proxy = proxy or self._get_proxy_from_env()
        if self.proxy:
            self._setup_proxy()
            self.logger.info(f"ä½¿ç”¨ Proxy: {self.proxy}")
        else:
            self.logger.info("æœªä½¿ç”¨ Proxyï¼ˆç›´é€£ï¼‰")

    def _get_proxy_from_env(self) -> Optional[str]:
        """å¾ç’°å¢ƒè®Šæ•¸æˆ– .env è®€å– proxy è¨­å®š"""
        proxy = os.environ.get('STOCK_PROXY') or os.environ.get('HTTP_PROXY')

        if not proxy:
            env_file = '.env'
            if os.path.exists(env_file):
                try:
                    with open(env_file, 'r', encoding='utf-8') as f:
                        for line in f:
                            line = line.strip()
                            if line.startswith('STOCK_PROXY='):
                                proxy = line.split('=', 1)[1].strip()
                                break
                except Exception as e:
                    self.logger.debug(f"è®€å– .env å¤±æ•—: {e}")

        return proxy

    def _setup_proxy(self):
        """è¨­å®š yfinance çš„ proxy"""
        import requests
        os.environ['HTTP_PROXY'] = self.proxy
        os.environ['HTTPS_PROXY'] = self.proxy

    def download(self, symbol: str, start: Optional[str] = None,
                 period: str = '500d') -> Optional[pd.DataFrame]:
        """
        å¾ yfinance ä¸‹è¼‰è³‡æ–™ (ä¿®æ­£ç‰ˆï¼šå¼·åˆ¶æŠ“å–åŸå§‹è‚¡åƒ¹)
        """
        try:
            download_symbol = symbol
            if '.TW' in symbol or '.TWO' in symbol:
                download_symbol = symbol.replace('_', '.')

            self.logger.debug(f"ä¸‹è¼‰ä»£è™Ÿ: {download_symbol}")

            ticker = yf.Ticker(download_symbol)

            # ğŸ”¥ é—œéµä¿®æ­£ 1ï¼šå¼·åˆ¶ä¸å¾©æ¬Šï¼Œè§£æ±ºå°æ•¸é»å•é¡Œ
            history_kwargs = {
                'auto_adjust': False,  # é—œé–‰è‡ªå‹•å¾©æ¬Š (é—œéµ!)
                'actions': True        # ä¿ç•™é™¤æ¬Šæ¯è³‡è¨Š
            }

            if start:
                history_kwargs['start'] = start
            else:
                history_kwargs['period'] = period

            df = ticker.history(**history_kwargs)

            if df.empty:
                self.logger.warning(f"ç„¡è³‡æ–™: {symbol}")
                return None

            # ğŸ”¥ é—œéµä¿®æ­£ 2ï¼šç§»é™¤ Adj Close ä¸¦çµ±ä¸€æ¬„ä½åç¨±
            if 'Adj Close' in df.columns:
                df = df.drop(columns=['Adj Close'])

            available_cols = df.columns.tolist()
            col_mapping = {
                'Open': 'open',
                'High': 'high',
                'Low': 'low',
                'Close': 'close',
                'Volume': 'volume'
            }

            selected_cols = [col for col in col_mapping.keys() if col in available_cols]
            df = df[selected_cols].copy()
            df.columns = [col_mapping[col] for col in selected_cols]

            if df.index.tz is not None:
                df.index = df.index.tz_localize(None)

            # ç¢ºä¿ Volume æ˜¯æ•´æ•¸
            if 'volume' in df.columns:
                df['volume'] = df['volume'].fillna(0).astype(int)

            self.logger.info(f"ä¸‹è¼‰ {symbol}: {len(df)} ç­†")
            return df

        except Exception as e:
            self.logger.error(f"ä¸‹è¼‰å¤±æ•— {symbol}: {e}")
            return None

    def update_single(self, symbol: str, force: bool = False, check_today: bool = True) -> Optional[pd.DataFrame]:
        """
        æ›´æ–°å–®ä¸€è‚¡ç¥¨ (æ”¯æ´å¼·åˆ¶é‡æŠ“é‚è¼¯)
        """
        self.logger.info(f"{'=' * 50}")
        self.logger.info(f"æ›´æ–°: {symbol}")

        # è¼‰å…¥ç¾æœ‰è³‡æ–™
        existing_df = self.cache.load(symbol)

        # æƒ…å¢ƒ1: é¦–æ¬¡ä¸‹è¼‰æˆ–å¼·åˆ¶æ›´æ–°
        if existing_df is None or force:
            reason = "å¼·åˆ¶æ›´æ–°" if force else "é¦–æ¬¡ä¸‹è¼‰"
            self.logger.info(f"{reason}ï¼Œä¸‹è¼‰å®Œæ•´è³‡æ–™...")
            df = self.download(symbol, period='500d')

        else:
            last_date = existing_df.index[-1]
            today = pd.Timestamp.now().normalize()
            missing_days = (today - last_date).days

            self.logger.info(f"æœ€å¾Œæ›´æ–°: {last_date.date()}, ç¼ºå¤± {missing_days} å¤©")

            if check_today and missing_days > 0:
                weekday = today.weekday()
                if weekday == 5:
                    expected_last_date = today - pd.Timedelta(days=1)
                elif weekday == 6:
                    expected_last_date = today - pd.Timedelta(days=2)
                else:
                    import datetime
                    now = datetime.datetime.now()
                    if now.hour < 14 or (now.hour == 14 and now.minute < 30):
                        expected_last_date = today - pd.Timedelta(days=1)
                    else:
                        expected_last_date = today

                if last_date >= expected_last_date:
                    self.logger.info(f"âœ“ è³‡æ–™å·²æ˜¯æœ€æ–° (æœ€å¾Œæ—¥æœŸ: {last_date.date()}, é æœŸ: {expected_last_date.date()})")
                    return existing_df
                else:
                    self.logger.info(f"éœ€è¦æ›´æ–° (é æœŸ: {expected_last_date.date()})")

            if missing_days <= 30:
                self.logger.info(f"å¢é‡æ›´æ–° {missing_days} å¤©...")
                start_date = (last_date + pd.Timedelta(days=1)).strftime('%Y-%m-%d')
                new_df = self.download(symbol, start=start_date)

                if new_df is not None and not new_df.empty:
                    df = self.cache.merge_data(existing_df, new_df)
                    self.logger.info(f"âœ“ æ–°å¢ {len(new_df)} ç­†è³‡æ–™")
                else:
                    self.logger.info("ç„¡æ–°è³‡æ–™ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥ï¼‰")
                    df = existing_df
            else:
                self.logger.warning(f"ç¼ºå¤±éä¹… ({missing_days} å¤©)ï¼Œé‡æ–°ä¸‹è¼‰...")
                df = self.download(symbol, period='500d')

        if df is not None:
            if existing_df is None or not existing_df.equals(df):
                if self.cache.save(symbol, df):
                    return df
            else:
                self.logger.info("âœ“ è³‡æ–™ç„¡è®ŠåŒ–ï¼Œä¸æ›´æ–°æª”æ¡ˆ")
                return df

        return None

    # ğŸ”¥ é—œéµä¿®æ­£ 3ï¼šåŠ å…¥ force åƒæ•¸ä¸¦å‚³éçµ¦å–®æª”æ›´æ–°
    def batch_update(self, symbols: List[str], max_workers: int = 3,
                     delay: float = 0.5, force: bool = False) -> Dict[str, List[str]]:
        """
        æ‰¹æ¬¡æ›´æ–°å¤šæª”è‚¡ç¥¨ (æ”¯æ´å‚³é force æŒ‡ä»¤)
        """
        self.logger.info(f"\n{'=' * 60}")
        self.logger.info(f"æ‰¹æ¬¡æ›´æ–°é–‹å§‹: {len(symbols)} æª”è‚¡ç¥¨")
        self.logger.info(f"å¹³è¡Œæ•¸é‡: {max_workers}")
        self.logger.info(f"å¼·åˆ¶æ¨¡å¼: {'æ˜¯' if force else 'å¦'}") # ğŸ‘ˆ æª¢æŸ¥é€™è£¡
        self.logger.info(f"{'=' * 60}\n")

        results = {'success': [], 'failed': []}
        start_time = time.time()

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            for symbol in symbols:
                # ğŸ”¥ é€™è£¡æŠŠ force å‚³éä¸‹å»
                future = executor.submit(self.update_single, symbol, force=force)
                futures[future] = symbol
                time.sleep(delay)

            for i, future in enumerate(as_completed(futures), 1):
                symbol = futures[future]
                try:
                    result = future.result()
                    if result is not None:
                        results['success'].append(symbol)
                        self.logger.info(f"[{i}/{len(symbols)}] âœ“ {symbol}")
                    else:
                        results['failed'].append(symbol)
                except Exception as e:
                    self.logger.error(f"[{i}/{len(symbols)}] âœ— {symbol}: {e}")
                    results['failed'].append(symbol)

        elapsed = time.time() - start_time
        self._save_update_log(results, elapsed)
        return results

    # ğŸ”¥ é—œéµä¿®æ­£ 4ï¼šè®“æœ€å¤–å±¤å‡½å¼ä¹Ÿæ”¯æ´å‚³é force
    def batch_update_with_progress(self, symbols: List[str],
                                   batch_size: int = 200,
                                   max_workers: int = 3,
                                   force: bool = False) -> Dict[str, List[str]]:
        """
        åˆ†æ‰¹æ¬¡æ›´æ–° (æ”¯æ´å‚³é force æŒ‡ä»¤)
        """
        total_results = {'success': [], 'failed': []}
        total_batches = (len(symbols) + batch_size - 1) // batch_size

        self.logger.info(f"\n{'=' * 60}")
        self.logger.info(f"åˆ†æ‰¹æ›´æ–°é–‹å§‹ (å¼·åˆ¶æ¨¡å¼: {'æ˜¯' if force else 'å¦'})") # ğŸ‘ˆ æª¢æŸ¥é€™è£¡
        self.logger.info(f"{'=' * 60}\n")

        for i in range(0, len(symbols), batch_size):
            batch_num = i // batch_size + 1
            batch = symbols[i:i + batch_size]

            self.logger.info(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_num}/{total_batches}")
            # ğŸ”¥ é€™è£¡æŠŠ force å‚³éä¸‹å»
            results = self.batch_update(batch, max_workers=max_workers, force=force)

            total_results['success'].extend(results['success'])
            total_results['failed'].extend(results['failed'])

            if batch_num < total_batches:
                time.sleep(10)

        return total_results

    def _save_update_log(self, results: Dict[str, List[str]], elapsed: float):
        """å„²å­˜æ›´æ–°æ—¥èªŒ (ç•¥)"""
        # ... (ä¿æŒåŸæ¨£) ...
        pass

    def _update_summary(self):
        """æ›´æ–°çµ±è¨ˆ (ç•¥)"""
        # ... (ä¿æŒåŸæ¨£) ...
        pass