# ==================================================
# ezmoney_parser.py
# è§£æ çµ±ä¸€æŠ•ä¿¡ ezmoney ETF æ¯æ—¥æŒè‚¡ Excel
# ==================================================

import pandas as pd
from pathlib import Path


class EZMoneyParser:
    """EZMoney ETF è³‡æ–™è§£æå™¨"""

    def __init__(self, raw_dir, clean_dir, etf_code="00981A"):
        """
        Args:
            raw_dir: åŸå§‹è³‡æ–™ç›®éŒ„
            clean_dir: æ¸…ç†å¾Œè³‡æ–™ç›®éŒ„
            etf_code: ETF ä»£ç¢¼
        """
        self.raw_dir = Path(raw_dir)
        self.clean_dir = Path(clean_dir)
        self.etf_code = etf_code
        self.out_file = Path(clean_dir) / f"{etf_code}.csv"

    def parse_excel(self, file_path: Path) -> pd.DataFrame:
        """
        è§£æå–®å€‹ Excelï¼ˆåªè®€ã€ŒæŒè‚¡æ˜ç´°ã€åˆ†é ï¼‰
        å›å‚³æ¨™æº–æ¬„ä½ DataFrame
        ä¿®æ­£ Bug: æ¯”å° Excel å…§éƒ¨æ—¥æœŸèˆ‡æª”åæ—¥æœŸï¼Œè‹¥ä¸ç¬¦å‰‡è¦–ç‚ºé‡è¤‡è³‡æ–™å‰”é™¤
        """
        # 1ï¸âƒ£ è®€å–ã€ŒæŒè‚¡æ˜ç´°ã€åˆ†é 
        try:
            df = pd.read_excel(file_path, sheet_name="æŒè‚¡æ˜ç´°")
        except ValueError:
            raise ValueError(f"âŒ {file_path.name} æ‰¾ä¸åˆ°ã€æŒè‚¡æ˜ç´°ã€åˆ†é ")

        # 2ï¸âƒ£ æ¬„ä½ alias å°æ‡‰
        column_map = {
            "è‚¡ç¥¨ä»£ç¢¼": "stock_code",
            "è‚¡ç¥¨ä»£è™Ÿ": "stock_code",
            "è‚¡ç¥¨åç¨±": "stock_name",
            "æŒè‚¡æ•¸": "shares",
            "å€¼ä½”æ¯”(%)": "weight",
            "æ·¨å€¼ä½”æ¯”(%)": "weight",
            "æ›´æ–°æ—¥æœŸ": "date",
        }

        # 3ï¸âƒ£ ç¯©å‡ºæˆ‘å€‘è¦çš„æ¬„ä½
        available_cols = {}
        for raw_col, std_col in column_map.items():
            if raw_col in df.columns:
                available_cols[raw_col] = std_col

        required_std_cols = {"stock_code", "stock_name", "shares", "weight", "date"}
        if set(available_cols.values()) != required_std_cols:
            raise KeyError(
                f"âŒ {file_path.name} æ¬„ä½ä¸å®Œæ•´\n"
                f"ç›®å‰æ¬„ä½ï¼š{df.columns.tolist()}"
            )

        df = df[list(available_cols.keys())].rename(columns=available_cols)

        # 4ï¸âƒ£ æ•¸å­—æ¬„ä½æ¸…ç†
        df["shares"] = (
            df["shares"]
            .astype(str)
            .str.replace(",", "", regex=False)
            .astype(float)  # å…ˆè½‰ float ä»¥è™•ç† 1445000.0 é€™ç¨®å­—ä¸²
            .astype(int)
        )

        df["weight"] = (
            df["weight"]
            .astype(str)
            .str.replace("%", "", regex=False)
            .astype(float)
        )

        # 5ï¸âƒ£ æ—¥æœŸæ ¼å¼çµ±ä¸€èˆ‡æ ¡é©— Bug ä¿®æ­£
        df["date"] = pd.to_datetime(df["date"]).dt.strftime("%Y-%m-%d")

        # âœ¨ Bug ä¿®æ­£æ ¸å¿ƒï¼šæª¢æŸ¥å…§éƒ¨æ—¥æœŸèˆ‡æª”æ¡ˆåç¨±æ—¥æœŸæ˜¯å¦ä¸€è‡´
        # æª”åå¯èƒ½æ˜¯ 2026_02_12.xlsxï¼Œè½‰æ›ç‚º 2026-02-12
        file_date_str = file_path.stem.replace('_', '-')
        internal_date_str = df["date"].iloc[0]

        if internal_date_str != file_date_str:
            # å¦‚æœæ—¥æœŸä¸ç¬¦ï¼ˆä¾‹å¦‚ 2/12 æª”æ¡ˆå…§å¯«çš„æ˜¯ 2/11 è³‡æ–™ï¼‰ï¼Œå›å‚³ç©ºè¡¨ä¸äºˆè§£æ
            print(f"âš ï¸  æ’é™¤é‡è¤‡è³‡æ–™: {file_path.name} (å…§éƒ¨æ—¥æœŸ {internal_date_str} èˆ‡æª”åä¸ç¬¦)")
            return pd.DataFrame(columns=['stock_code', 'stock_name', 'shares', 'weight', 'date'])

        # 6ï¸âƒ£ ç¢ºä¿è³‡æ–™ä¸é‡è¤‡ (é›™é‡ä¿éšª)
        df = df.drop_duplicates(subset=['stock_code', 'date'], keep='last')

        return df
    def parse_all_files(self):
        """è§£ææ‰€æœ‰æª”æ¡ˆä¸¦è¼¸å‡º CSV"""
        # 1ï¸âƒ£ é˜²å‘†ï¼šRAW_DIR å¿…é ˆå­˜åœ¨
        if not self.raw_dir.exists():
            raise FileNotFoundError(f"âŒ RAW_DIR ä¸å­˜åœ¨ï¼š{self.raw_dir}")

        # 2ï¸âƒ£ æ‰¾åˆ°æ‰€æœ‰ Excel
        files = sorted(self.raw_dir.rglob("*.xls*"))
        if not files:
            print(f"âš ï¸ RAW_DIR åº•ä¸‹æ‰¾ä¸åˆ° Excel æª”æ¡ˆï¼š{self.raw_dir}")
            return

        print(f"ğŸ“‚ æ‰¾åˆ° {len(files)} å€‹ Excelï¼Œé–‹å§‹è§£æ {self.etf_code} ...")

        # 3ï¸âƒ£ è§£ææ‰€æœ‰ Excel
        all_rows = []
        for f in files:
            try:
                all_rows.append(self.parse_excel(f))
            except Exception as e:
                print(f"âš ï¸ è§£æå¤±æ•—ï¼š{f.name}")
                print(e)

        if not all_rows:
            raise RuntimeError("âŒ æ²’æœ‰ä»»ä½•æª”æ¡ˆæˆåŠŸè§£æ")

        # 4ï¸âƒ£ åˆä½µ DataFrame
        result = pd.concat(all_rows, ignore_index=True)
        # âœ¨ æ–°å¢é˜²å‘†ï¼šç¢ºä¿åŒæ—¥æœŸã€åŒä»£ç¢¼çš„è‚¡ç¥¨åªæœƒå‡ºç¾ä¸€ç­†ï¼ˆä¿ç•™æœ€å¾Œä¸€ç­†ï¼‰
        result = result.drop_duplicates(subset=['date', 'stock_code'], keep='last')

        # 5ï¸âƒ£ æ’åºï¼ˆæ—¥æœŸ + æ¬Šé‡ï¼‰
        result = result.sort_values(
            by=["date", "weight"], ascending=[True, False]
        )

        # 6ï¸âƒ£ å»ºç«‹ clean è³‡æ–™å¤¾
        self.out_file.parent.mkdir(parents=True, exist_ok=True)

        # 7ï¸âƒ£ è¼¸å‡º CSV
        result.to_csv(self.out_file, index=False, encoding="utf-8-sig")

        print(f"âœ… è§£æå®Œæˆï¼Œè¼¸å‡ºåˆ°ï¼š{self.out_file}")


# ä¿ç•™åŸæœ¬çš„åŸ·è¡Œæ–¹å¼
def run():
    """å‘ä¸‹ç›¸å®¹ï¼šèˆŠçš„åŸ·è¡Œæ–¹å¼"""
    BASE_DIR = Path(__file__).resolve().parents[3]  # èª¿æ•´ç‚ºå°ˆæ¡ˆæ ¹ç›®éŒ„
    raw_dir = BASE_DIR / "æˆ°æƒ…å®¤" / "data" / "raw" / "ezmoney" / "00981A"
    clean_dir = BASE_DIR / "æˆ°æƒ…å®¤" / "data" / "clean" / "ezmoney"

    parser = EZMoneyParser(raw_dir, clean_dir)
    parser.parse_all_files()


if __name__ == "__main__":
    run()