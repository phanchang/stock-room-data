import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os
from datetime import datetime

# ==================================================
# 1. å°ˆæ¡ˆè·¯å¾‘åˆå§‹åŒ–
# ==================================================
current_file = Path(__file__).resolve()
project_root = current_file.parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


class StrategyAnalyzer:
    """ä¸»å‹•å¼ ETF ç­–ç•¥åˆ†æå™¨ï¼šæ•´åˆå¤šæŠ•ä¿¡ç±Œç¢¼å‹•å‘"""

    def __init__(self):
        self.clean_dir = project_root / "data" / "clean"
        self.all_data = []
        self.latest_report_dates = {}

    def load_all_clean_data(self):
        """å‹•æ…‹æƒæ data/clean ä¸‹æ‰€æœ‰æŠ•ä¿¡çš„ CSV æª”æ¡ˆä¸¦æ¨™æº–åŒ–"""
        print(f"ğŸ” æ­£åœ¨æƒæè³‡æ–™å¤¾: {self.clean_dir}")
        for csv_file in self.clean_dir.rglob("*.csv"):
            if csv_file.name.startswith("._") or "stock_list" in csv_file.name:
                continue
            try:
                df = pd.read_csv(csv_file)
                df['date'] = pd.to_datetime(df['date'])
                id_col = 'stock_code' if 'stock_code' in df.columns else 'stock_id'
                df = df.drop_duplicates(subset=['date', id_col], keep='last')

                # æ¬„ä½åˆ¥åè™•ç†
                df = df.rename(columns={
                    'stock_code': 'stock_id',
                    'code': 'stock_id',
                    'stock_name': 'name'
                })

                df['stock_id'] = df['stock_id'].astype(str)
                # æ¨™è¨˜ä¾†æº e.g., capitalfund_00982A
                source_tag = f"{csv_file.parent.name}_{csv_file.stem}"
                df['etf_source'] = source_tag

                self.all_data.append(df)
            except Exception as e:
                print(f"âš ï¸ è®€å–æª”æ¡ˆ {csv_file.name} ç™¼ç”ŸéŒ¯èª¤: {e}")

    def get_individual_diffs(self):
        """é‡å°æ¯æª” ETF ç¨ç«‹è¨ˆç®—å…¶æœ€å¾Œå…©å€‹äº¤æ˜“æ—¥çš„å¢æ¸›"""
        all_diffs = []

        for df in self.all_data:
            source = df['etf_source'].iloc[0]
            dates = sorted(df['date'].unique())

            if len(dates) < 2:
                print(f"â„¹ï¸ {source} è³‡æ–™å¤©æ•¸ä¸è¶³ï¼Œè·³éæ¯”å°")
                continue

            latest_t = dates[-1]
            prev_t = dates[-2]
            self.latest_report_dates[source] = latest_t.strftime('%Y-%m-%d')

            # æå–æœ€æ–°èˆ‡å‰ä¸€æ¬¡è³‡æ–™
            df_now = df[df['date'] == latest_t].copy()
            df_prev = df[df['date'] == prev_t].copy()

            # åˆä½µæ¯”å°
            merged = pd.merge(
                df_now, df_prev,
                on=['stock_id', 'name', 'etf_source'],
                how='outer',
                suffixes=('_now', '_prev')
            ).fillna(0)

            # è¨ˆç®—è‚¡æ•¸è®Šå‹•
            merged['shares_diff'] = merged['shares_now'] - merged['shares_prev']

            # ğŸ’¡ é—œéµï¼šéæ¿¾æ‰æ²’æœ‰è®Šå‹•çš„ï¼Œä»¥åŠè³£å‡ºçš„ï¼ˆæˆ‘å€‘å°ˆæ³¨æ–¼è²·å…¥å…±è­˜ï¼‰
            merged = merged[merged['shares_diff'] > 0]

            # æ¨™è¨˜æ˜¯å¦ç‚ºã€Œæ–°é€²æ¦œã€
            merged['action'] = np.where(merged['shares_prev'] == 0, "ğŸ†•æ–°è²·å…¥", "ğŸ“ˆå¢æŒ")

            all_diffs.append(merged)

        return pd.concat(all_diffs, ignore_index=True) if all_diffs else pd.DataFrame()

    def generate_ai_prompt(self, diff_df):
            """ç”¢å‡ºé¤µçµ¦ Gemini çš„æ·±åº¦åˆ†æ Prompt (å¼·åŒ–å®¢è§€ã€å…¨é¢èˆ‡æŸ¥è­‰ç´€å¾‹)"""

            # 1. è™•ç†å…±è­˜æ¨™çš„ (Consensus)
            consensus = diff_df.groupby(['stock_id', 'name']).agg({
                'etf_source': 'count',
                'shares_diff': 'sum',
                'weight_now': 'mean',
                'action': lambda x: "/".join(set(x))
            }).rename(columns={'etf_source': 'æŠ•ä¿¡å®¶æ•¸', 'shares_diff': 'ç¸½åŠ ç¢¼è‚¡æ•¸',
                               'weight_now': 'å¹³å‡æ¬Šé‡(%)'}).sort_values('æŠ•ä¿¡å®¶æ•¸', ascending=False)

            consensus_table = consensus[consensus['æŠ•ä¿¡å®¶æ•¸'] > 1].reset_index()

            # 2. è™•ç†é»‘é¦¬æ¨™çš„ (Top Buys)
            dark_horses = diff_df.sort_values('shares_diff', ascending=False).head(15)
            # æ¬„ä½ä¸­æ–‡åŒ–èˆ‡ç¾åŒ–
            dark_horses_table = dark_horses[
                ['stock_id', 'name', 'etf_source', 'action', 'shares_diff', 'weight_now']].rename(
                columns={
                    'stock_id': 'ä»£è™Ÿ', 'name': 'åç¨±', 'etf_source': 'ETFä¾†æº',
                    'action': 'å‹•ä½œ', 'shares_diff': 'åŠ ç¢¼è‚¡æ•¸', 'weight_now': 'ç•¶å‰æ¬Šé‡(%)'
                }
            )

            # 3. çµ„è£æ—¥æœŸ Metadata
            date_meta = "\n".join([f"- {k}: {v}" for k, v in self.latest_report_dates.items()])

            # 4. å»ºç«‹ Markdown (å°å…¥å¼·æ ¼å¼èˆ‡åš´æ ¼æŸ¥è­‰æŒ‡ä»¤)
            prompt = f"""# ğŸ“… å°è‚¡ä¸»å‹•å¼ ETF ç±Œç¢¼äº¤å‰æˆ°æƒ…å ±è¡¨

    ## ğŸ“Š ç¬¬ä¸€éšæ®µï¼šé‡åŒ–æ•¸æ“šåŸºæº– (å®¢è§€äº‹å¯¦)
    **è³‡æ–™åº«åŸºæº–æ—¥ï¼š**
    {date_meta}

    ### ğŸ¯ æŠ•ä¿¡é«˜åº¦å…±è­˜æ¨™çš„ (å¤šæª” ETF åŒæ­¥å¢æŒ)
    > èªªæ˜ï¼šä¸‹è¡¨ç‚ºè·¨å®¶æŠ•ä¿¡åŒæ™‚è²·å…¥çš„å€‹è‚¡ã€‚å…±è­˜åº¦è¶Šé«˜ï¼Œä»£è¡¨æ³•äººè³‡é‡‘åŒ¯èšçš„å®¢è§€äº‹å¯¦ã€‚
    {consensus_table.to_markdown(index=False) if not consensus_table.empty else "ä»Šæ—¥æš«ç„¡å¤šå®¶å…±è­˜æ¨™çš„ã€‚"}

    ### ğŸš€ å–®ä¸€æŠ•ä¿¡é¡¯è‘—åŠ ç¢¼/æ–°é€²æ¦œé»‘é¦¬ (Top 15)
    > èªªæ˜ï¼šä¸‹è¡¨ç‚ºå„å®¶ ETF å–®æ—¥åŠ ç¢¼å¼µæ•¸æœ€é¡¯è‘—çš„æ¨™çš„ã€‚
    {dark_horses_table.to_markdown(index=False) if not dark_horses_table.empty else "ç„¡æ˜é¡¯åŠ ç¢¼æ¨™çš„ã€‚"}

    ---

    ## ğŸ¤– ç¬¬äºŒéšæ®µï¼šAI æ·±åº¦ç ”ç©¶èˆ‡å®¢è§€åˆ†ææŒ‡ä»¤

    ä½ æ˜¯ä¸€ä½å…·å‚™ 20 å¹´ç¶“é©—çš„å°è‚¡é‡åŒ–èˆ‡åŸºæœ¬é¢æ“ç›¤æ‰‹ã€‚è«‹åŸºæ–¼ä¸Šæ–¹ã€ç¬¬ä¸€éšæ®µã€‘çš„å®¢è§€ç±Œç¢¼æ•¸æ“šï¼ŒåŸ·è¡Œä»¥ä¸‹åˆ†æä»»å‹™ã€‚

    âš ï¸ ã€æœ€é«˜æŒ‡å°åŸå‰‡ï¼šçµ•å°å®¢è§€èˆ‡çœŸå¯¦ã€‘âš ï¸
    1. å¼•ç”¨æ•¸æ“šåšæ¨ç†èˆ‡ç ”ç©¶ã€Œå¿…é ˆã€ä½¿ç”¨ Google search é€²è¡Œå¤šæ–¹ä¾†æºäº¤å‰æŸ¥è­‰ã€‚
    2. çµ•ä¸å…è¨±è‡ªå·±ç”¢ç”Ÿã€æé€ æˆ–çŒœæ¸¬çœŸå¯¦æ•¸æ“šã€‚
    3. å¼•ç”¨ä»»ä½•æ•¸æ“šåšå‘ˆç¾æˆ–è¨ˆç®—ï¼Œå¿…é ˆåœ¨è©²æ®µè½æ˜ç¢ºé™„ä¸Šã€Œä¾†æºç¶²ç«™èˆ‡è³‡æ–™å‡ºè™•ã€ã€‚

    ### ğŸ” ä»»å‹™ 1ï¼šè³‡é‡‘æ¿å¡Šèˆ‡ç”¢æ¥­ç¶œè§€ (Macroscopic View)
    è«‹å®¢è§€è§€å¯Ÿä¸Šæ–¹çš„ã€Œå…±è­˜æ¨™çš„ã€èˆ‡ã€Œé»‘é¦¬æ¨™çš„ã€ï¼Œæ­¸ç´å‡ºç›®å‰æŠ•ä¿¡è³‡é‡‘æ­£åœ¨æµå‘å“ªäº›ã€Œå…·é«”ç”¢æ¥­ã€æˆ–ã€Œæ¦‚å¿µæ¿å¡Šã€ï¼ˆä¾‹å¦‚ï¼šAI ä¼ºæœå™¨ã€ç¶²é€šã€ä½åŸºæœŸå‚³ç”¢ç­‰ï¼‰ã€‚
    * **è¦æ±‚**ï¼šè«‹ç”¨ 1-2 æ®µè©±ç²¾è¦ç¸½çµç›®å‰çš„è³‡é‡‘è¼ªå»“ï¼Œä¸å¯éåº¦ç™¼æ•£ï¼Œåƒ…é‡å°æœ‰å‡ºç¾åœ¨ä¸Šæ–¹è¡¨æ ¼çš„æ¨™çš„é€²è¡Œç”¢æ¥­åˆ†é¡æ­¸ç´ã€‚

    ### ğŸ•µï¸â€â™‚ï¸ ä»»å‹™ 2ï¼šé‡é»æ¨™çš„åŸºæœ¬é¢èˆ‡äº‹ä»¶æŸ¥è­‰ (Fact-Checking)
    é‡å°ã€Œå…±è­˜æ¨™çš„ã€æ¸…å–®ï¼Œä»¥åŠã€Œé»‘é¦¬æ¨™çš„ã€ä¸­åŠ ç¢¼æœ€é¡¯è‘—çš„å‰ä¸‰åå€‹è‚¡ï¼Œå¼·åˆ¶ä½¿ç”¨ Google æœå°‹æŸ¥è­‰è¿‘ä¸€é€±å…§çš„é‡å¤§äº‹ä»¶ã€‚
    * **è¼¸å‡ºæ ¼å¼è¦æ±‚**ï¼šè«‹ä»¥ã€Œè¡¨æ ¼ã€å‘ˆç¾æŸ¥è­‰çµæœï¼Œå¿…é ˆåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
      | è‚¡ç¥¨åç¨± | è¿‘æœŸå‚¬åŒ–åŠ‘ (æ³•èªªæœƒ/ç‡Ÿæ”¶/è²¡å ±ç­‰å®¢è§€äº‹å¯¦) | æ³•äºº/å¤–è³‡å‹•æ…‹æ–°è | è³‡æ–™ä¾†æº (å¿…é ˆé™„ä¸Š URL æˆ–æ˜ç¢ºçš„åª’é«”ä¾†æº) |

    ### ğŸ¯ ä»»å‹™ 3ï¼šæ˜æ—¥å®¢è§€äº¤æ˜“è§€å¯Ÿæ¸…å–® (Actionable & Predictable)
    ç¶œåˆã€Œç±Œç¢¼å…±è­˜æ•¸æ“šã€èˆ‡ã€Œä»»å‹™ 2 çš„ç¶²è·¯æŸ¥è­‰äº‹å¯¦ã€ï¼Œå®¢è§€ç¯©é¸å‡ºæ˜æ—©é–‹ç›¤æœ€å€¼å¾—é—œæ³¨çš„ 3 æª”è‚¡ç¥¨ã€‚
    * **è¼¸å‡ºæ ¼å¼è¦æ±‚**ï¼šè«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹æ ¼å¼æ¢åˆ—ï¼Œç¢ºä¿æ¯æ¬¡è¼¸å‡ºçš„å¯é æ¸¬æ€§ã€‚
      1. **[è‚¡ç¥¨ä»£è™Ÿ/åç¨±]**
         * **ç±Œç¢¼é¢å®¢è§€äº‹å¯¦**ï¼š(å¦‚ï¼š2å®¶æŠ•ä¿¡å…±è­˜è²·å…¥ï¼Œæˆ–å–®ä¸€æŠ•ä¿¡å¤§è²· XX è‚¡)
         * **åŸºæœ¬é¢/æ¶ˆæ¯é¢æ”¯æ’**ï¼š(å¼•ç”¨ä»»å‹™ 2 æŸ¥è­‰åˆ°çš„äº‹å¯¦ï¼Œä¸¦é™„è¨»ä¾†æº)
         * **æŠ€è¡“é¢/å‹æ…‹è§€å¯Ÿé»**ï¼š(è‹¥èƒ½æœå°‹åˆ°è¿‘æœŸè‚¡åƒ¹ä½éšæˆ–æ³•äººç›®æ¨™åƒ¹ï¼Œè«‹å®¢è§€åˆ—å‡ºï¼›è‹¥ç„¡å‰‡å¯«ã€Œç„¡ç‰¹æ®Šè³‡è¨Šã€)
    """
            return prompt

    def run(self):
        print(f"=== æˆ°æƒ…å®¤åˆ†æç³»çµ±å•Ÿå‹•: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===")

        self.load_all_clean_data()
        if not self.all_data:
            print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ä»»ä½• clean è³‡æ–™ï¼Œè«‹å…ˆåŸ·è¡Œçˆ¬èŸ²èˆ‡ Parserã€‚")
            return

        diff_df = self.get_individual_diffs()

        if not diff_df.empty:
            prompt = self.generate_ai_prompt(diff_df)

            # å„²å­˜åˆ° data è³‡æ–™å¤¾
            output_path = project_root / "data" / "daily_ai_prompt.txt"
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(prompt)

            print(f"\nâœ… åˆ†æå ±è¡¨ç”¢å‡ºæˆåŠŸï¼")
            print(f"ğŸ“ æª”æ¡ˆä½ç½®: {output_path}")
            print("-" * 50)
            print("ğŸ’¡ æ“ä½œæç¤ºï¼šè«‹å°‡æª”æ¡ˆå…§å®¹è²¼çµ¦ Gemini 1.5 æˆ– 2.0 Proï¼Œè®“å®ƒé–‹å§‹åŸ·è¡Œç¶²è·¯æŸ¥è­‰èˆ‡ç ”å ±æ’°å¯«ã€‚")
            print("-" * 50)
        else:
            print("âš ï¸ è­¦å‘Šï¼šè¨ˆç®—å¾Œç„¡ä»»ä½•è‚¡æ•¸è®Šå‹•è³‡æ–™ï¼ˆå¯èƒ½ä»Šæ—¥å„æŠ•ä¿¡çš†æœªæ›´æ–°è‚¡æ•¸ï¼‰ã€‚")


if __name__ == "__main__":
    analyzer = StrategyAnalyzer()
    analyzer.run()