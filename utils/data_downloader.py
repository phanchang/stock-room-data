import pandas as pd
import requests
from pathlib import Path
import time


class DataDownloader:
    def __init__(self):
        self.base_url = "https://raw.githubusercontent.com/phanchang/stock-room-data/main"
        self.cache_dir = Path("data/cache")
        self.tw_cache = self.cache_dir / "tw"

        self.tw_cache.mkdir(parents=True, exist_ok=True)

        # ğŸ”¥ [Cache] è¨˜æ†¶é«”å¿«å–ï¼š{ "2330": ("TW", df_obj), ... }
        # é€™æ¨£ç¬¬äºŒæ¬¡å­˜å–åŒä¸€æª”è‚¡ç¥¨æ™‚ï¼Œé€£ç¡¬ç¢Ÿéƒ½ä¸ç”¨è®€ï¼Œç›´æ¥å¾ RAM æ‹¿
        self.memory_cache = {}

    def update_stock_list_from_github(self):
        """ å¾ GitHub ä¸‹è¼‰æœ€æ–°çš„è‚¡ç¥¨æ¸…å–® """
        url = f"{self.base_url}/data/stock_list.csv"
        local_path = Path("data/stock_list.csv")
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                with open(local_path, 'wb') as f:
                    f.write(response.content)
                return True
        except Exception as e:
            print(f"âŒ æ¸…å–®ä¸‹è¼‰å¤±æ•—: {e}")
        return False

    def discover_market(self, stock_id):
        """
        è‡ªå‹•åµæ¸¬å¸‚å ´ (TW vs TWO) + è¨˜æ†¶é«”å¿«å–
        å„ªå…ˆé †åº: RAM -> Disk -> Network
        """
        # 1. ğŸ”¥ ç¬¬ä¸€å±¤ï¼šæª¢æŸ¥è¨˜æ†¶é«”å¿«å– (æœ€å¿«)
        if stock_id in self.memory_cache:
            # print(f"âš¡ [RAM] ç§’è®€å¿«å–: {stock_id}")
            return self.memory_cache[stock_id]

        # 2. ç¬¬äºŒå±¤ï¼šæª¢æŸ¥æœ¬åœ°ç¡¬ç¢Ÿ (Parquet)
        for mkt in ["TW", "TWO"]:
            local_path = self.tw_cache / f"{stock_id}_{mkt}.parquet"
            if local_path.exists():
                try:
                    df = pd.read_parquet(local_path)
                    # å­˜å…¥è¨˜æ†¶é«”å¿«å–
                    self.memory_cache[stock_id] = (mkt, df)
                    return mkt, df
                except:
                    pass

                    # 3. ç¬¬ä¸‰å±¤ï¼šé›²ç«¯è©¦éŒ¯ (æœ€æ…¢ï¼Œåªåœ¨ç¬¬ä¸€æ¬¡ç™¼ç”Ÿ)
        # å…ˆè©¦ TW
        df = self._download_parquet(stock_id, "TW")
        if df is not None:
            self.memory_cache[stock_id] = ("TW", df)
            return "TW", df

        # å†è©¦ TWO
        df = self._download_parquet(stock_id, "TWO")
        if df is not None:
            self.memory_cache[stock_id] = ("TWO", df)
            return "TWO", df

        # çœŸçš„æ‰¾ä¸åˆ°
        return "TW", None

    def update_kline_data(self, stock_id, market):
        """ æŒ‡å®šå¸‚å ´ä¸‹è¼‰ (èˆŠç›¸å®¹æ¨¡å¼) """
        # 1. æª¢æŸ¥è¨˜æ†¶é«”
        if stock_id in self.memory_cache:
            cached_market, cached_df = self.memory_cache[stock_id]
            if cached_market == market:
                return cached_df

        local_path = self.tw_cache / f"{stock_id}_{market}.parquet"

        # 2. æª¢æŸ¥ç¡¬ç¢Ÿ
        if local_path.exists():
            try:
                df = pd.read_parquet(local_path)
                self.memory_cache[stock_id] = (market, df)  # æ›´æ–°å¿«å–
                return df
            except:
                pass

        # 3. ä¸‹è¼‰
        df = self._download_parquet(stock_id, market)
        if df is not None:
            self.memory_cache[stock_id] = (market, df)  # æ›´æ–°å¿«å–

        return df

    def _download_parquet(self, stock_id, market):
        """ å…§éƒ¨æ–¹æ³•ï¼šåŸ·è¡Œå¯¦éš›ä¸‹è¼‰ """
        filename = f"{stock_id}_{market}.parquet"
        url = f"{self.base_url}/data/cache/tw/{filename}"
        local_path = self.tw_cache / filename

        try:
            # print(f"â˜ï¸ [Network] ä¸‹è¼‰ä¸­: {filename}")
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                with open(local_path, 'wb') as f:
                    f.write(response.content)
                return pd.read_parquet(local_path)
        except Exception as e:
            pass

        return None