import pandas as pd
import numpy as np
from pathlib import Path
import sys
from datetime import datetime

# ==================================================
# 1. å°ˆæ¡ˆè·¯å¾‘åˆå§‹åŒ–
# ==================================================
current_file = Path(__file__).resolve()
project_root = current_file.parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


class StrategyAnalyzer:
    """ä¸»å‹•å¼ ETF ç­–ç•¥åˆ†æå™¨ï¼šé›™æ¦œå–®ç³»çµ± (é‡é‡‘æŠ¼å¯¶æ¦œ vs æ½›ä¼å·è²·æ¦œ)"""

    def __init__(self):
        self.clean_dir = project_root / "data" / "clean"
        self.cache_dir = project_root / "data" / "cache" / "tw"
        self.all_data = []
        self.stock_market_map = {}
        self.latest_report_date = None

        self.load_market_info()

    def load_market_info(self):
        csv_path = project_root / "data" / "stock_list.csv"
        if csv_path.exists():
            try:
                for enc in ['utf-8', 'utf-8-sig', 'big5']:
                    try:
                        df = pd.read_csv(csv_path, dtype=str, encoding=enc)
                        df.columns = [c.lower().strip() for c in df.columns]
                        code_col = next((col for col in ['stock_id', 'code', 'id'] if col in df.columns), None)

                        if code_col and 'market' in df.columns:
                            for _, row in df.iterrows():
                                sid = str(row[code_col]).strip()
                                market = str(row['market']).strip().upper()
                                self.stock_market_map[sid] = market
                            break
                    except:
                        continue
            except Exception as e:
                print(f"âŒ è®€å–å¸‚å ´è³‡è¨Šå¤±æ•—: {e}")

    def get_market_suffix(self, stock_id):
        return self.stock_market_map.get(str(stock_id), "TW")

    def load_all_clean_data(self):
        print(f"ğŸ” æ­£åœ¨æƒæè³‡æ–™å¤¾: {self.clean_dir}")
        for csv_file in self.clean_dir.rglob("*.csv"):
            if csv_file.name.startswith("._") or "stock_list" in csv_file.name:
                continue
            try:
                df = pd.read_csv(csv_file)
                df['date'] = pd.to_datetime(df['date'])
                id_col = 'stock_code' if 'stock_code' in df.columns else 'stock_id'

                df = df.rename(columns={id_col: 'stock_id', 'stock_name': 'name'})
                df['stock_id'] = df['stock_id'].astype(str)
                df['etf_source'] = f"{csv_file.parent.name}_{csv_file.stem}"

                for col in ['shares', 'weight']:
                    if col in df.columns and df[col].dtype == 'object':
                        df[col] = df[col].astype(str).str.replace(',', '').str.replace('%', '')
                        df[col] = pd.to_numeric(df[col], errors='coerce')

                self.all_data.append(df)
            except Exception as e:
                pass

    def analyze_dual_leaderboards(self):
        """è¨ˆç®—é›™æ¦œå–®æ‰€éœ€çš„æ‰€æœ‰æ­·å²èˆ‡åƒ¹æ ¼ç‰¹å¾µ"""
        if not self.all_data: return pd.DataFrame()

        combined_df = pd.concat(self.all_data, ignore_index=True)
        daily_summary = combined_df.groupby(['date', 'stock_id', 'name'])['shares'].sum().reset_index()

        dates = sorted(daily_summary['date'].unique())
        if len(dates) < 5:
            print("âš ï¸ æ­·å²è³‡æ–™éå°‘ï¼Œç„¡æ³•åˆ†æã€‚")
            return pd.DataFrame()

        self.latest_report_date = dates[-1].strftime('%Y-%m-%d')

        t_now = dates[-1]
        t_5 = dates[-5] if len(dates) >= 5 else dates[0]
        t_20 = dates[-20] if len(dates) >= 20 else dates[0]
        t_60 = dates[-60] if len(dates) >= 60 else dates[0]

        analysis_results = []
        stocks = daily_summary['stock_id'].unique()

        print(f"ğŸ“ˆ å•Ÿå‹•é›™æ¦œå–®ç±Œç¢¼è¿½è¹¤å¼•æ“...")

        for stock_id in stocks:
            stock_data = daily_summary[daily_summary['stock_id'] == stock_id].sort_values('date')
            name = stock_data['name'].iloc[0]

            def get_shares(t_date):
                return stock_data[stock_data['date'] == t_date]['shares'].sum() if t_date in stock_data[
                    'date'].values else 0

            shares_now = get_shares(t_now)
            shares_5d_ago = get_shares(t_5)
            shares_20d_ago = get_shares(t_20)
            shares_60d_ago = get_shares(t_60)

            diff_5d = shares_now - shares_5d_ago
            diff_20d = shares_now - shares_20d_ago
            diff_60d = shares_now - shares_60d_ago

            # æ¢ä»¶éæ¿¾ï¼šæˆ‘å€‘åªçœ‹ã€Œè¿‘5å¤©æœ‰åœ¨è²·ã€çš„æ´»æ°´è‚¡
            if diff_5d <= 0: continue

            market = self.get_market_suffix(stock_id)
            price_path = self.cache_dir / f"{stock_id}_{market}.parquet"

            current_price = 0
            estimated_cost_60d = 0
            net_buy_value_60d = 0

            if price_path.exists():
                try:
                    price_df = pd.read_parquet(price_path)
                    price_df.columns = [c.capitalize() for c in price_df.columns]
                    price_df.index = pd.to_datetime(price_df.index).tz_localize(None)

                    if not price_df.empty:
                        current_price = price_df.iloc[-1]['Close']

                        stock_data_60 = stock_data[stock_data['date'] >= t_60].copy()
                        stock_data_60['share_change'] = stock_data_60['shares'].diff().fillna(0)

                        total_buy_cost = 0
                        total_buy_shares = 0

                        for _, row in stock_data_60.iterrows():
                            if row['share_change'] > 0:
                                p_date = row['date']
                                if p_date in price_df.index:
                                    daily_price = price_df.loc[p_date, 'Close']
                                else:
                                    nearest_idx = price_df.index.get_indexer([p_date], method='nearest')[0]
                                    daily_price = price_df.iloc[nearest_idx]['Close']

                                total_buy_cost += (row['share_change'] * daily_price)
                                total_buy_shares += row['share_change']

                        if total_buy_shares > 0:
                            estimated_cost_60d = total_buy_cost / total_buy_shares
                            net_buy_value_60d = total_buy_cost / 10000

                except Exception:
                    pass

            analysis_results.append({
                'ä»£è™Ÿ': stock_id,
                'åç¨±': name,
                'ç•¶å‰è‚¡æ•¸': shares_now,
                '20æ—¥å‰è‚¡æ•¸': shares_20d_ago,
                'è¿‘5æ—¥å¢æ¸›': diff_5d,
                'è¿‘20æ—¥å¢æ¸›': diff_20d,
                'ä¸€å­£è€—è³‡(è¬)': round(net_buy_value_60d, 0),
                'æœ€æ–°æ”¶ç›¤åƒ¹': current_price,
                'æŠ•ä¿¡å­£æˆæœ¬': round(estimated_cost_60d, 2)
            })

        result_df = pd.DataFrame(analysis_results)
        if result_df.empty: return result_df

        result_df['ä¹–é›¢(%)'] = np.where(result_df['æŠ•ä¿¡å­£æˆæœ¬'] > 0,
                                        ((result_df['æœ€æ–°æ”¶ç›¤åƒ¹'] - result_df['æŠ•ä¿¡å­£æˆæœ¬']) / result_df[
                                            'æŠ•ä¿¡å­£æˆæœ¬'] * 100), 0)
        result_df['ä¹–é›¢(%)'] = result_df['ä¹–é›¢(%)'].round(2)

        return result_df

    def generate_ai_prompt(self, df):
        """ç”¢å‡ºé›™æ¦œå–®èˆ‡é˜²å¹»è¦ºæŸ¥è­‰æŒ‡ä»¤çš„ AI Prompt"""

        # ==========================================
        # æ¦œå–® Aï¼šé‡é‡‘æŠ¼å¯¶æ¦œ (ä¾è€—è³‡é‡‘é¡æ’åº Top 15)
        # ==========================================
        list_a = df.sort_values('ä¸€å­£è€—è³‡(è¬)', ascending=False).head(15).copy()
        # æ ¼å¼åŒ–é¡¯ç¤º
        list_a['ç•¶å‰è‚¡æ•¸'] = list_a['ç•¶å‰è‚¡æ•¸'].apply(lambda x: f"{x:,}")
        list_a_view = list_a[
            ['ä»£è™Ÿ', 'åç¨±', 'ç•¶å‰è‚¡æ•¸', 'è¿‘5æ—¥å¢æ¸›', 'è¿‘20æ—¥å¢æ¸›', 'ä¸€å­£è€—è³‡(è¬)', 'æŠ•ä¿¡å­£æˆæœ¬', 'ä¹–é›¢(%)']]

        # ==========================================
        # æ¦œå–® Bï¼šæ½›ä¼å·è²·æ¦œ (éæ¿¾æ‰ List Aï¼Œæ‰¾å‡º 20 æ—¥å‰ç„¡åº«å­˜ï¼Œæˆ–è¿‘æœŸæ‰é–‹å§‹è²·çš„æ¨™çš„)
        # ==========================================
        exclude_ids = list_a['ä»£è™Ÿ'].tolist()
        list_b_candidates = df[~df['ä»£è™Ÿ'].isin(exclude_ids)].copy()

        # æ¢ä»¶ï¼š20 æ—¥å‰åº«å­˜ç‚º 0 (å¾ç„¡åˆ°æœ‰)ï¼Œä¸”è¿‘ 5 æ—¥æœ‰è²·é€²ã€‚æˆ–æ˜¯è¿‘ 5 æ—¥è²·è¶…ä½”äº†è¿‘ 20 æ—¥çµ•å¤§æ¯”ä¾‹ã€‚
        stealth_mask = (list_b_candidates['20æ—¥å‰è‚¡æ•¸'] == 0) | (
                    list_b_candidates['è¿‘5æ—¥å¢æ¸›'] == list_b_candidates['è¿‘20æ—¥å¢æ¸›'])
        list_b = list_b_candidates[stealth_mask].sort_values('è¿‘5æ—¥å¢æ¸›', ascending=False).head(15)

        list_b['ç•¶å‰è‚¡æ•¸'] = list_b['ç•¶å‰è‚¡æ•¸'].apply(lambda x: f"{x:,}")
        list_b_view = list_b[
            ['ä»£è™Ÿ', 'åç¨±', 'ç•¶å‰è‚¡æ•¸', 'è¿‘5æ—¥å¢æ¸›', 'è¿‘20æ—¥å¢æ¸›', 'ä¸€å­£è€—è³‡(è¬)', 'æŠ•ä¿¡å­£æˆæœ¬', 'ä¹–é›¢(%)']]

        prompt = f"""# ğŸ“… å°è‚¡ä¸»å‹•å¼ ETF ã€é›™æ¦œå–®ã€‘ç±Œç¢¼æˆ°æƒ…å ±è¡¨

## ğŸ“Š ç¬¬ä¸€éšæ®µï¼šé‡åŒ–æ•¸æ“šåŸºæº–
**è³‡æ–™åº«åŸºæº–æ—¥ï¼š** {self.latest_report_date}

### ğŸ† æ¦œå–® Aï¼šé‡é‡‘æŠ¼å¯¶æ¦œ (Top 15 ä¸»åŠ›è³‡é‡‘æµå‘)
> èªªæ˜ï¼šæŠ•ä¿¡è¿‘ä¸€å­£ç ¸ä¸‹æœ€å¤šã€Œçµ•å°é‡‘é¡ã€çš„æ ¸å¿ƒæ¨™çš„ã€‚è«‹è—‰æ­¤è§€å¯Ÿå¤§ç›¤çš„ä¸»æµç”¢æ¥­èˆ‡è³‡é‡‘èšè½ã€‚
{list_a_view.to_markdown(index=False) if not list_a_view.empty else "ç„¡ç¬¦åˆæ¢ä»¶æ¨™çš„"}

### ğŸ¥· æ¦œå–® Bï¼šç ´è›‹æ½›ä¼å·è²·æ¦œ (Top 15 é›¶åˆ°ä¸€é»‘é¦¬)
> èªªæ˜ï¼šé€™äº›æ¨™çš„çµ•å°é‡‘é¡ä¸å¤§ï¼Œä½†ç‰¹å¾µæ˜¯ã€Œéå» 20 å¤©æ²’è²·ï¼Œæœ€è¿‘ 5 å¤©çªç„¶é€£çºŒè²·é€² / å¾é›¶å»ºå€‰ã€ã€‚é€™é€šå¸¸æ˜¯æ³•äººæŒæ¡äº†æœªå…¬é–‹çš„è³‡è¨Šè½å·®ï¼Œæ­£åœ¨å·¦å´é»˜é»˜åƒè²¨ã€‚
{list_b_view.to_markdown(index=False) if not list_b_view.empty else "ç„¡ç¬¦åˆæ¢ä»¶æ¨™çš„"}

---

## ğŸ¤– ç¬¬äºŒéšæ®µï¼šAI æ“ç›¤æ‰‹æ·±åº¦æ¨æ–·èˆ‡ã€å¼·åˆ¶å¤šæ–¹æŸ¥è­‰æŒ‡ä»¤ã€‘

ä½ æ˜¯ä¸€ä½å…·å‚™ 20 å¹´ç¶“é©—çš„å°è‚¡é‡åŒ–èˆ‡åŸºæœ¬é¢æ“ç›¤æ‰‹ã€‚è«‹åŸºæ–¼ä¸Šæ–¹é›™æ¦œå–®åŸ·è¡Œåˆ†æã€‚

âš ï¸ ã€æœ€é«˜æŒ‡å°åŸå‰‡ï¼šçµ•å°å®¢è§€èˆ‡çœŸå¯¦ã€‘âš ï¸
1. å¼•ç”¨æ•¸æ“šåšæ¨ç†èˆ‡ç ”ç©¶ã€Œå¿…é ˆã€ä½¿ç”¨ Google search é€²è¡Œå¤šæ–¹ä¾†æºäº¤å‰æŸ¥è­‰ã€‚
2. çµ•ä¸å…è¨±è‡ªå·±ç”¢ç”Ÿã€æé€ æˆ–çŒœæ¸¬çœŸå¯¦æ•¸æ“šã€‚
3. å¼•ç”¨ä»»ä½•æ•¸æ“šåšå‘ˆç¾æˆ–è¨ˆç®—ï¼Œå¿…é ˆåœ¨è©²æ®µè½æ˜ç¢ºé™„ä¸Šã€Œä¾†æºç¶²ç«™èˆ‡è³‡æ–™å‡ºè™•ã€ã€‚

### ğŸ” ä»»å‹™ 1ï¼šä¸»æµæ¿å¡Š vs æ½›ä¼æ¿å¡Šå°æ¯”åˆ†æ
* è§€å¯Ÿã€æ¦œå–® Aã€‘ï¼Œç›®å‰æŠ•ä¿¡é‡å…µé›†çµåœ¨å“ª 1~2 å€‹ç”¢æ¥­ï¼Ÿ
* è§€å¯Ÿã€æ¦œå–® Bã€‘ï¼ŒæŠ•ä¿¡æ­£åœ¨å·å·ä½ˆå±€å“ªäº›ã€Œå†·é–€ã€æˆ–ã€Œä½åŸºæœŸã€ç”¢æ¥­ï¼Ÿé€™æ˜¯å¦æš—ç¤ºè³‡é‡‘æœ‰é«˜ä½ä½éšè½‰æ›çš„è·¡è±¡ï¼Ÿ

### ğŸ•µï¸â€â™‚ï¸ ä»»å‹™ 2ï¼šé›™æ¦œå–®æ ¸å¿ƒæ¨™çš„å®¢è§€äº‹å¯¦æŸ¥è­‰ (Fact-Checking)
è«‹å¾ã€æ¦œå–® Aã€‘æŒ‘é¸ 2 æª”ï¼Œå¾ã€æ¦œå–® Bã€‘æŒ‘é¸ 2 æª”ï¼Œ**å¼·åˆ¶ä½¿ç”¨ Google æœå°‹æŸ¥è­‰**è¿‘ä¸€å€‹æœˆå…§çš„é‡å¤§äº‹ä»¶ï¼ˆç‡Ÿæ”¶ã€æ³•èªªæœƒã€å¤–è³‡å ±å‘Šç­‰ï¼‰ã€‚
* **ç‰¹åˆ¥é˜²å‘†æŒ‡ä»¤**ï¼šå°æ–¼ã€æ¦œå–® Bã€‘çš„æ½›ä¼è‚¡ï¼Œ**å¦‚æœä½ æŸ¥ä¸åˆ°ä»»ä½•è¿‘æœŸåˆ©å¤šæ–°èï¼Œè«‹ç›´æ¥åœ¨è¡¨æ ¼ä¸­å¯«æ˜ã€Œç¶“å¤šæ–¹æŸ¥è­‰ï¼Œç„¡è¿‘æœŸç›¸é—œæ–°èç™¼å¸ƒã€**ã€‚é€™æ˜¯éå¸¸é‡è¦çš„å®¢è§€äº‹å¯¦ï¼Œä»£è¡¨è©²è‚¡æ­£è™•æ–¼ã€Œç„¡è²å»ºå€‰æœŸã€ï¼Œçµ•å°ç¦æ­¢æé€ åˆ©å¤šï¼
* **è¼¸å‡ºæ ¼å¼è¦æ±‚**ï¼š(è«‹ä»¥ Markdown è¡¨æ ¼å‘ˆç¾)
  | æ‰€å±¬æ¦œå–® | è‚¡ç¥¨åç¨± | è¿‘æœŸçœŸå¯¦å‚¬åŒ–åŠ‘ (æŸ¥ç„¡æ–°èè«‹èª å¯¦å¡«å¯«) | è³‡æ–™ä¾†æº (å¿…é ˆé™„ä¸Š URL æˆ–åª’é«”åç¨±) |

### ğŸ¯ ä»»å‹™ 3ï¼šæ˜æ—¥å¯¦æˆ°äº¤æ˜“æ¸…å–®æ¨æ–· (Actionable Plan)
åŸºæ–¼æ³•äººç±Œç¢¼ç¯€å¥èˆ‡ä½ çš„å®¢è§€æŸ¥è­‰ï¼ŒæŒ‘é¸å‡º 3 æª”æœ€å€¼å¾—åˆ—å…¥æ˜æ—¥è§€å¯Ÿåå–®çš„è‚¡ç¥¨ã€‚
* **æ¨è–¦é‚è¼¯**ï¼š
  - è‹¥æ¨è–¦ã€æ¦œå–® Aã€‘æ¨™çš„ï¼šéœ€èªªæ˜å…¶è¶¨å‹¢å‹•èƒ½ï¼Œä¸¦è©•ä¼°ç›®å‰çš„ã€Œä¹–é›¢ç‡ã€æ˜¯å¦æœ‰è¿½é«˜é¢¨éšªã€‚
  - è‹¥æ¨è–¦ã€æ¦œå–® Bã€‘æ¨™çš„ï¼šéœ€èªªæ˜ç‚ºä½•åœ¨ã€Œæ²’æœ‰æ˜é¡¯æ–°èã€çš„æƒ…æ³ä¸‹ï¼ŒæŠ•ä¿¡çš„ã€Œå¾é›¶å»ºå€‰ã€è¡Œç‚ºå€¼å¾—è·Ÿéš¨ï¼ˆä¾‹å¦‚ï¼šä¸‹æª”å…·å‚™æŠ•ä¿¡æˆæœ¬ä¿è­·ï¼Œå‹ç‡æ¥µé«˜ï¼‰ã€‚
* è«‹ä¾åºæ¢åˆ—é€™ 3 æª”ï¼Œä¸¦å†æ¬¡é™„ä¸Šæ”¯æ’ä½ è«–é»çš„è³‡æ–™å‡ºè™•ã€‚
"""
        return prompt

    def run(self):
        print(f"=== æˆ°æƒ…å®¤é›™æ¦œå–®åˆ†æç³»çµ±å•Ÿå‹•: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===")

        self.load_all_clean_data()
        result_df = self.analyze_dual_leaderboards()

        if not result_df.empty:
            prompt = self.generate_ai_prompt(result_df)

            output_path = project_root / "data" / "daily_ai_prompt.txt"
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, "w", encoding="utf-8") as f:
                f.write(prompt)

            print(f"\nâœ… é›™æ¦œå–®æ·±åº¦åˆ†æå ±è¡¨ç”¢å‡ºæˆåŠŸï¼")
            print(f"ğŸ“ æª”æ¡ˆä½ç½®: {output_path}")
            print("-" * 50)
            print("ğŸ’¡ æç¤ºï¼šç¾åœ¨ AI èƒ½å¤ æ˜ç¢ºå€åˆ†ã€Œé‡é‡‘å‹•èƒ½è‚¡ã€èˆ‡ã€Œç„¡è²æ½›ä¼è‚¡ã€äº†ï¼Œå¿«è²¼çµ¦ Gemini æ¸¬è©¦çœ‹çœ‹ï¼")
            print("-" * 50)
        else:
            print("âš ï¸ è­¦å‘Šï¼šç„¡æ³•è¨ˆç®—å‡ºæ³¢æ®µæ•¸æ“šã€‚")


if __name__ == "__main__":
    analyzer = StrategyAnalyzer()
    analyzer.run()